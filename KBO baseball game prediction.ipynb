{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "0cb6a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.utils import plot_model #모델 시각화 \n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, TensorBoard\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f1e863",
   "metadata": {},
   "source": [
    "## 데이터 불러오기\n",
    "- 앞서 크롤링하여 엑셀에 저장한 파일을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "729929ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_excel('baseball_data.xlsx')\n",
    "target_df = pd.read_excel('label.xlsx')\n",
    "try:\n",
    "    del data_df['Unnamed: 0']\n",
    "    del target_df['Unnamed: 0']\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389ef69",
   "metadata": {},
   "source": [
    "## 훈련세트, 검증세트, 테스트세트 분리\n",
    "- 8:2비율로 훈련세트, 테스트 세트를 분리하고 또 다시 8:2로 훈련세트, 검증세트를 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "61cc75dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>타석</th>\n",
       "      <th>타수</th>\n",
       "      <th>안타</th>\n",
       "      <th>홈런</th>\n",
       "      <th>볼넷</th>\n",
       "      <th>사구</th>\n",
       "      <th>삼진</th>\n",
       "      <th>땅볼</th>\n",
       "      <th>플라이</th>\n",
       "      <th>팀타율</th>\n",
       "      <th>잔루</th>\n",
       "      <th>상대선발투수ERA</th>\n",
       "      <th>상대선발투수WHIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>9</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>12</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>19</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>15</td>\n",
       "      <td>6.57</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>30</td>\n",
       "      <td>4.82</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>11</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>15</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>22</td>\n",
       "      <td>8.10</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>13</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>7</td>\n",
       "      <td>7.46</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2464 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      타석  타수  안타  홈런  볼넷  사구  삼진  땅볼  플라이       팀타율  잔루  상대선발투수ERA  상대선발투수WHIP\n",
       "1362  42  34  10   2   6   1   9   9    6  0.294118   9       9.55        2.19\n",
       "3844  37  33   7   0   2   2  12   8    6  0.212121  12       4.56        1.51\n",
       "3695  37  34   7   1   3   0  10   9    8  0.205882  19       2.45        1.17\n",
       "3424  37  35  10   1   1   1  10   9    6  0.285714  15       6.57        1.91\n",
       "2934  46  38  11   0   7   1   7  12    8  0.289474  30       4.82        1.35\n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ...       ...  ..        ...         ...\n",
       "3532  37  36  11   1   0   1   6   6   13  0.305556  11       2.72        1.11\n",
       "84    39  36  10   0   2   0   7   9   10  0.277778  15       1.83        1.00\n",
       "1600  48  44  19   1   4   0  12   7    6  0.431818  22       8.10        2.10\n",
       "1287  36  34   9   2   2   0   8   5   12  0.264706  13       4.35        1.43\n",
       "2020  30  28   6   2   1   0   5  12    5  0.214286   7       7.46        2.01\n",
       "\n",
       "[2464 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#훈련세트, 검증세트, 테스 트세트 분리 \n",
    "X_full_set, X_test=  train_test_split(data_df, test_size = 0.2, random_state = 7)\n",
    "y_full_set, y_test = train_test_split(target_df, test_size = 0.2, random_state = 7)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_full_set,y_full_set, test_size=0.2, random_state=7)\n",
    "display(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cc53c",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "- min-max 스케일링(정규화) 와 표준화 둘 중 더 좋은걸로 선택\n",
    "- 전처리 하지 않는걸로..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "id": "b3ec4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 정규화\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_full_set)\n",
    "\n",
    "X_full_set = scaler.transform(X_full_set)\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val=scaler.transform(x_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5817e",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "id": "dc8aa4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14216\\2324621434.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 3ms/step - loss: 32.7408 - val_loss: 25.1914\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 21.3752 - val_loss: 17.5499\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 15.4605 - val_loss: 13.1855\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 11.7778 - val_loss: 10.2959\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 9.2350 - val_loss: 8.2944\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 7.4474 - val_loss: 6.8794\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.1705 - val_loss: 5.8605\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.2531 - val_loss: 5.1059\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.5723 - val_loss: 4.5520\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.0747 - val_loss: 4.1490\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.7111 - val_loss: 3.8444\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4401 - val_loss: 3.6133\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2359 - val_loss: 3.4409\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0846 - val_loss: 3.3089\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9684 - val_loss: 3.2076\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8820 - val_loss: 3.1269\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8134 - val_loss: 3.0642\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7602 - val_loss: 3.0129\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7182 - val_loss: 2.9707\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6836 - val_loss: 2.9370\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6556 - val_loss: 2.9063\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6332 - val_loss: 2.8805\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6145 - val_loss: 2.8599\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5985 - val_loss: 2.8414\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5838 - val_loss: 2.8271\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5730 - val_loss: 2.8131\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5624 - val_loss: 2.7988\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5529 - val_loss: 2.7880\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5448 - val_loss: 2.7765\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5379 - val_loss: 2.7676\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5311 - val_loss: 2.7603\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.5251 - val_loss: 2.7524\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.5200 - val_loss: 2.7455\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5157 - val_loss: 2.7407\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5117 - val_loss: 2.7337\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5077 - val_loss: 2.7260\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5045 - val_loss: 2.7200\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5008 - val_loss: 2.7165\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4976 - val_loss: 2.7124\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4950 - val_loss: 2.7092\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4924 - val_loss: 2.7064\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4899 - val_loss: 2.7026\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4879 - val_loss: 2.7010\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4856 - val_loss: 2.6986\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4836 - val_loss: 2.6948\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4818 - val_loss: 2.6942\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4801 - val_loss: 2.6893\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4794 - val_loss: 2.6878\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4776 - val_loss: 2.6884\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4763 - val_loss: 2.6863\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4744 - val_loss: 2.6849\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4738 - val_loss: 2.6833\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4724 - val_loss: 2.6787\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4708 - val_loss: 2.6764\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4701 - val_loss: 2.6744\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4692 - val_loss: 2.6736\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4685 - val_loss: 2.6735\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4683 - val_loss: 2.6717\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4673 - val_loss: 2.6693\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4667 - val_loss: 2.6668\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4656 - val_loss: 2.6672\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4649 - val_loss: 2.6656\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4645 - val_loss: 2.6636\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4636 - val_loss: 2.6625\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4621 - val_loss: 2.6612\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4625 - val_loss: 2.6607\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4616 - val_loss: 2.6598\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4612 - val_loss: 2.6586\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.4602 - val_loss: 2.6576\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.4600 - val_loss: 2.6580\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4590 - val_loss: 2.6563\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4591 - val_loss: 2.6568\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4581 - val_loss: 2.6569\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4580 - val_loss: 2.6583\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4576 - val_loss: 2.6569\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4570 - val_loss: 2.6578\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4573 - val_loss: 2.6554\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4565 - val_loss: 2.6550\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4559 - val_loss: 2.6535\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4552 - val_loss: 2.6528\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4551 - val_loss: 2.6509\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4549 - val_loss: 2.6504\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4540 - val_loss: 2.6493\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4543 - val_loss: 2.6493\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4531 - val_loss: 2.6489\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4524 - val_loss: 2.6486\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4527 - val_loss: 2.6467\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4518 - val_loss: 2.6500\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4526 - val_loss: 2.6482\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4517 - val_loss: 2.6464\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4512 - val_loss: 2.6451\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4499 - val_loss: 2.6441\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4504 - val_loss: 2.6440\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4495 - val_loss: 2.6427\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4492 - val_loss: 2.6414\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4499 - val_loss: 2.6431\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4489 - val_loss: 2.6417\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4481 - val_loss: 2.6407\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4477 - val_loss: 2.6398\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.4477 - val_loss: 2.6397\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.4842\n",
      "[CV] END learning_rate=0.0015777568092806976, n_hidden=0, n_neurons=60; total time=  10.4s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 33.6573 - val_loss: 24.9343\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 21.5950 - val_loss: 17.1648\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 15.3495 - val_loss: 12.7703\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 11.5554 - val_loss: 9.9281\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 9.0023 - val_loss: 7.9491\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 7.2197 - val_loss: 6.5503\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.9560 - val_loss: 5.5385\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.0432 - val_loss: 4.7992\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.3771 - val_loss: 4.2669\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.8981 - val_loss: 3.8771\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.5484 - val_loss: 3.5935\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2945 - val_loss: 3.3842\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1063 - val_loss: 3.2279\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9667 - val_loss: 3.1129\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8667 - val_loss: 3.0274\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7912 - val_loss: 2.9619\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7330 - val_loss: 2.9133\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6905 - val_loss: 2.8731\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6563 - val_loss: 2.8418\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6294 - val_loss: 2.8190\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6098 - val_loss: 2.7990\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5929 - val_loss: 2.7831\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5795 - val_loss: 2.7705\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5696 - val_loss: 2.7592\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5595 - val_loss: 2.7487\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5522 - val_loss: 2.7391\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5456 - val_loss: 2.7316\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5389 - val_loss: 2.7255\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5347 - val_loss: 2.7217\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5300 - val_loss: 2.7167\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5265 - val_loss: 2.7137\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5229 - val_loss: 2.7115\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5201 - val_loss: 2.7095\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5169 - val_loss: 2.7056\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5142 - val_loss: 2.7036\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5120 - val_loss: 2.7004\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5102 - val_loss: 2.6983\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5079 - val_loss: 2.6973\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5059 - val_loss: 2.6948\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5041 - val_loss: 2.6928\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5030 - val_loss: 2.6923\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5009 - val_loss: 2.6881\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4998 - val_loss: 2.6872\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4980 - val_loss: 2.6827\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4979 - val_loss: 2.6812\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4966 - val_loss: 2.6807\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4952 - val_loss: 2.6793\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4939 - val_loss: 2.6787\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4928 - val_loss: 2.6778\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4921 - val_loss: 2.6766\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4913 - val_loss: 2.6761\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4911 - val_loss: 2.6741\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4905 - val_loss: 2.6709\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4891 - val_loss: 2.6678\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4881 - val_loss: 2.6666\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4880 - val_loss: 2.6667\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4871 - val_loss: 2.6659\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4866 - val_loss: 2.6654\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4865 - val_loss: 2.6678\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4853 - val_loss: 2.6685\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4848 - val_loss: 2.6665\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4840 - val_loss: 2.6651\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4832 - val_loss: 2.6639\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4823 - val_loss: 2.6647\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4825 - val_loss: 2.6643\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4819 - val_loss: 2.6634\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4815 - val_loss: 2.6624\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4808 - val_loss: 2.6645\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4805 - val_loss: 2.6617\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4808 - val_loss: 2.6599\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4797 - val_loss: 2.6579\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4795 - val_loss: 2.6569\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4793 - val_loss: 2.6562\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4783 - val_loss: 2.6552\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4783 - val_loss: 2.6553\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4776 - val_loss: 2.6561\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4771 - val_loss: 2.6544\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4767 - val_loss: 2.6542\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4766 - val_loss: 2.6521\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4764 - val_loss: 2.6524\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4759 - val_loss: 2.6527\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4757 - val_loss: 2.6551\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4758 - val_loss: 2.6540\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4757 - val_loss: 2.6534\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4745 - val_loss: 2.6523\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4747 - val_loss: 2.6509\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4735 - val_loss: 2.6501\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4730 - val_loss: 2.6490\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4722 - val_loss: 2.6503\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4730 - val_loss: 2.6507\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.4722 - val_loss: 2.6479\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4721 - val_loss: 2.6476\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4714 - val_loss: 2.6458\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4711 - val_loss: 2.6476\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4710 - val_loss: 2.6475\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4707 - val_loss: 2.6470\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4698 - val_loss: 2.6472\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4701 - val_loss: 2.6460\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4695 - val_loss: 2.6459\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4689 - val_loss: 2.6432\n",
      "26/26 [==============================] - 0s 892us/step - loss: 2.4352\n",
      "[CV] END learning_rate=0.0015777568092806976, n_hidden=0, n_neurons=60; total time=   9.8s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 28.9329 - val_loss: 24.0440\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 19.8301 - val_loss: 17.3261\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 14.6512 - val_loss: 13.1387\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 11.2461 - val_loss: 10.2549\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 8.8642 - val_loss: 8.2164\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 7.1586 - val_loss: 6.7508\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.9277 - val_loss: 5.6797\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.0231 - val_loss: 4.8908\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.3594 - val_loss: 4.3238\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.8816 - val_loss: 3.9106\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.5301 - val_loss: 3.6096\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2755 - val_loss: 3.3886\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0860 - val_loss: 3.2252\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9456 - val_loss: 3.1036\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8392 - val_loss: 3.0111\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7571 - val_loss: 2.9430\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6983 - val_loss: 2.8913\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6529 - val_loss: 2.8519\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6172 - val_loss: 2.8227\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5890 - val_loss: 2.7982\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5668 - val_loss: 2.7792\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5503 - val_loss: 2.7650\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5353 - val_loss: 2.7545\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5239 - val_loss: 2.7439\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5132 - val_loss: 2.7358\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5047 - val_loss: 2.7284\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4970 - val_loss: 2.7219\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4906 - val_loss: 2.7138\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4861 - val_loss: 2.7107\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4805 - val_loss: 2.7099\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4756 - val_loss: 2.7026\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4720 - val_loss: 2.6996\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4688 - val_loss: 2.6965\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4654 - val_loss: 2.6959\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4624 - val_loss: 2.6904\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4595 - val_loss: 2.6862\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4573 - val_loss: 2.6858\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4553 - val_loss: 2.6839\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4525 - val_loss: 2.6818\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4508 - val_loss: 2.6830\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4487 - val_loss: 2.6801\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4478 - val_loss: 2.6773\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4456 - val_loss: 2.6740\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4437 - val_loss: 2.6734\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4428 - val_loss: 2.6711\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4403 - val_loss: 2.6723\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4395 - val_loss: 2.6708\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4391 - val_loss: 2.6670\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4370 - val_loss: 2.6651\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4364 - val_loss: 2.6650\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4348 - val_loss: 2.6632\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4337 - val_loss: 2.6628\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4329 - val_loss: 2.6604\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4320 - val_loss: 2.6592\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4307 - val_loss: 2.6569\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4306 - val_loss: 2.6569\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4298 - val_loss: 2.6550\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4285 - val_loss: 2.6527\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.4279 - val_loss: 2.6529\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4270 - val_loss: 2.6521\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4272 - val_loss: 2.6501\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4262 - val_loss: 2.6488\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4256 - val_loss: 2.6510\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4248 - val_loss: 2.6484\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4240 - val_loss: 2.6492\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4232 - val_loss: 2.6483\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4228 - val_loss: 2.6484\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4222 - val_loss: 2.6477\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4215 - val_loss: 2.6478\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4206 - val_loss: 2.6455\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4202 - val_loss: 2.6445\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.4199 - val_loss: 2.6442\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4195 - val_loss: 2.6428\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4186 - val_loss: 2.6406\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4179 - val_loss: 2.6454\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4178 - val_loss: 2.6434\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4176 - val_loss: 2.6403\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.4171 - val_loss: 2.6385\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4161 - val_loss: 2.6400\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4160 - val_loss: 2.6395\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4154 - val_loss: 2.6391\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4150 - val_loss: 2.6355\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4146 - val_loss: 2.6357\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 2.4141 - val_loss: 2.6361\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4135 - val_loss: 2.6349\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4128 - val_loss: 2.6350\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4127 - val_loss: 2.6387\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4124 - val_loss: 2.6367\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4119 - val_loss: 2.6339\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4118 - val_loss: 2.6319\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4114 - val_loss: 2.6324\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4110 - val_loss: 2.6294\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4109 - val_loss: 2.6307\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4098 - val_loss: 2.6321\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4093 - val_loss: 2.6326\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4094 - val_loss: 2.6329\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4091 - val_loss: 2.6289\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4085 - val_loss: 2.6304\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4078 - val_loss: 2.6335\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4078 - val_loss: 2.6288\n",
      "26/26 [==============================] - 0s 919us/step - loss: 2.5115\n",
      "[CV] END learning_rate=0.0015777568092806976, n_hidden=0, n_neurons=60; total time=   9.6s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 18.9409 - val_loss: 8.0267\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 7.7788 - val_loss: 5.6701\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.6447 - val_loss: 4.6217\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.4958 - val_loss: 3.9177\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.7688 - val_loss: 3.4344\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3201 - val_loss: 3.1192\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0426 - val_loss: 2.9533\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8597 - val_loss: 2.7997\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7440 - val_loss: 2.7006\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6549 - val_loss: 2.6368\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5939 - val_loss: 2.5993\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5500 - val_loss: 2.5841\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5183 - val_loss: 2.5567\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4868 - val_loss: 2.5595\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4631 - val_loss: 2.5302\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4403 - val_loss: 2.5324\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4323 - val_loss: 2.5091\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4148 - val_loss: 2.5147\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4008 - val_loss: 2.4848\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3902 - val_loss: 2.4813\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3767 - val_loss: 2.4733\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3669 - val_loss: 2.4711\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3570 - val_loss: 2.4646\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3497 - val_loss: 2.4528\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3448 - val_loss: 2.4558\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3308 - val_loss: 2.4607\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3278 - val_loss: 2.4597\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3215 - val_loss: 2.4594\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3177 - val_loss: 2.4540\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3008 - val_loss: 2.4465\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2990 - val_loss: 2.4738\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3014 - val_loss: 2.4482\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2953 - val_loss: 2.4356\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2808 - val_loss: 2.4423\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2867 - val_loss: 2.4365\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2800 - val_loss: 2.4411\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2776 - val_loss: 2.4460\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2713 - val_loss: 2.4453\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2758 - val_loss: 2.4458\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2697 - val_loss: 2.4456\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2646 - val_loss: 2.4460\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2618 - val_loss: 2.4502\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2571 - val_loss: 2.4431\n",
      "26/26 [==============================] - 0s 944us/step - loss: 2.4017\n",
      "[CV] END learning_rate=0.0019239410919752438, n_hidden=1, n_neurons=10; total time=   4.5s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 23.1098 - val_loss: 9.1332\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.7629 - val_loss: 4.0074\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.7142 - val_loss: 3.2564\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1019 - val_loss: 3.0284\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8668 - val_loss: 2.9065\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7438 - val_loss: 2.8138\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6736 - val_loss: 2.7434\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6042 - val_loss: 2.6926\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5642 - val_loss: 2.6727\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5263 - val_loss: 2.6377\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4945 - val_loss: 2.6030\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4709 - val_loss: 2.5774\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4551 - val_loss: 2.5631\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4407 - val_loss: 2.5412\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4267 - val_loss: 2.5351\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4041 - val_loss: 2.5279\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4047 - val_loss: 2.5181\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3892 - val_loss: 2.5161\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3828 - val_loss: 2.5133\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3730 - val_loss: 2.5238\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3756 - val_loss: 2.5022\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3619 - val_loss: 2.5101\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3599 - val_loss: 2.5009\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3532 - val_loss: 2.5081\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3471 - val_loss: 2.4876\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3408 - val_loss: 2.4697\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3376 - val_loss: 2.4845\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3366 - val_loss: 2.4822\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3324 - val_loss: 2.4942\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3305 - val_loss: 2.4718\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3290 - val_loss: 2.4715\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3210 - val_loss: 2.4699\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3209 - val_loss: 2.4600\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3163 - val_loss: 2.4695\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3182 - val_loss: 2.4598\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3111 - val_loss: 2.4458\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3091 - val_loss: 2.4498\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3045 - val_loss: 2.4573\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3027 - val_loss: 2.4419\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3044 - val_loss: 2.4378\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2973 - val_loss: 2.4471\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2947 - val_loss: 2.4600\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2970 - val_loss: 2.4371\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2978 - val_loss: 2.4354\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2925 - val_loss: 2.4224\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2853 - val_loss: 2.4526\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2899 - val_loss: 2.4305\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2894 - val_loss: 2.4422\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2888 - val_loss: 2.4304\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2848 - val_loss: 2.4250\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2842 - val_loss: 2.4274\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2848 - val_loss: 2.4168\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2803 - val_loss: 2.4215\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2804 - val_loss: 2.4243\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2795 - val_loss: 2.4198\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2772 - val_loss: 2.4209\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2760 - val_loss: 2.4116\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2751 - val_loss: 2.4133\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2745 - val_loss: 2.4118\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2717 - val_loss: 2.4155\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2749 - val_loss: 2.4210\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2695 - val_loss: 2.4334\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2711 - val_loss: 2.4388\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2687 - val_loss: 2.4293\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2720 - val_loss: 2.4191\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2680 - val_loss: 2.4055\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2689 - val_loss: 2.4092\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2645 - val_loss: 2.4025\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2624 - val_loss: 2.4031\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2644 - val_loss: 2.4085\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2575 - val_loss: 2.4285\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2637 - val_loss: 2.4120\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2602 - val_loss: 2.4094\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2594 - val_loss: 2.4100\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2566 - val_loss: 2.3987\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2538 - val_loss: 2.3993\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2589 - val_loss: 2.4017\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2522 - val_loss: 2.3950\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2497 - val_loss: 2.4197\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2549 - val_loss: 2.3956\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2503 - val_loss: 2.3932\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2542 - val_loss: 2.3891\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2530 - val_loss: 2.3870\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2456 - val_loss: 2.3914\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2492 - val_loss: 2.3902\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2471 - val_loss: 2.3952\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2498 - val_loss: 2.4051\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2442 - val_loss: 2.3961\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.2414 - val_loss: 2.3947\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2401 - val_loss: 2.3927\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2461 - val_loss: 2.3922\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2427 - val_loss: 2.4057\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2401 - val_loss: 2.3952\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.3317\n",
      "[CV] END learning_rate=0.0019239410919752438, n_hidden=1, n_neurons=10; total time=   9.5s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 20.3317 - val_loss: 10.3793\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 8.3639 - val_loss: 6.8329\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.3353 - val_loss: 5.4242\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.0660 - val_loss: 4.4858\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.1792 - val_loss: 3.8493\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.5641 - val_loss: 3.4210\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1680 - val_loss: 3.1203\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9015 - val_loss: 2.9255\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7362 - val_loss: 2.8001\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6298 - val_loss: 2.7233\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5536 - val_loss: 2.6574\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5067 - val_loss: 2.6376\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4650 - val_loss: 2.6009\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4412 - val_loss: 2.5838\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4171 - val_loss: 2.5853\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4018 - val_loss: 2.5624\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3907 - val_loss: 2.5640\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3794 - val_loss: 2.5497\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3727 - val_loss: 2.5650\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3628 - val_loss: 2.5407\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3591 - val_loss: 2.5312\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3536 - val_loss: 2.5463\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3490 - val_loss: 2.5384\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3437 - val_loss: 2.5507\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3399 - val_loss: 2.5310\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3337 - val_loss: 2.5195\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3313 - val_loss: 2.5264\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3320 - val_loss: 2.5236\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3260 - val_loss: 2.5307\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3230 - val_loss: 2.5507\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3212 - val_loss: 2.5339\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3167 - val_loss: 2.5283\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3168 - val_loss: 2.5349\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3097 - val_loss: 2.5194\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3127 - val_loss: 2.5257\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3091 - val_loss: 2.5447\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3073 - val_loss: 2.5273\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3026 - val_loss: 2.5314\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3041 - val_loss: 2.5334\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3015 - val_loss: 2.5375\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3000 - val_loss: 2.5238\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2979 - val_loss: 2.5275\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2996 - val_loss: 2.5284\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2954 - val_loss: 2.5314\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.5767\n",
      "[CV] END learning_rate=0.0019239410919752438, n_hidden=1, n_neurons=10; total time=   4.7s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 19.5778 - val_loss: 8.0465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.4936 - val_loss: 4.8133\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.8435 - val_loss: 4.1950\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.1924 - val_loss: 3.8532\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.7805 - val_loss: 3.5444\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4782 - val_loss: 3.3427\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2576 - val_loss: 3.1842\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0965 - val_loss: 3.0623\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9685 - val_loss: 2.9527\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8658 - val_loss: 2.8746\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7847 - val_loss: 2.8113\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7207 - val_loss: 2.7577\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6678 - val_loss: 2.7054\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6203 - val_loss: 2.6739\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5827 - val_loss: 2.6497\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5462 - val_loss: 2.6066\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5173 - val_loss: 2.5842\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4942 - val_loss: 2.5694\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4747 - val_loss: 2.5471\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4577 - val_loss: 2.5325\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4370 - val_loss: 2.5227\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4259 - val_loss: 2.5026\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4134 - val_loss: 2.4912\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4007 - val_loss: 2.4899\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3935 - val_loss: 2.4798\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3823 - val_loss: 2.4805\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3715 - val_loss: 2.4645\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3661 - val_loss: 2.4631\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3575 - val_loss: 2.4582\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3497 - val_loss: 2.4540\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3431 - val_loss: 2.4527\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3379 - val_loss: 2.4437\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3327 - val_loss: 2.4420\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3245 - val_loss: 2.4335\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3202 - val_loss: 2.4412\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3158 - val_loss: 2.4344\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3106 - val_loss: 2.4374\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3087 - val_loss: 2.4356\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3010 - val_loss: 2.4298\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2983 - val_loss: 2.4279\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2945 - val_loss: 2.4203\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2878 - val_loss: 2.4187\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2852 - val_loss: 2.4180\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2796 - val_loss: 2.4141\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2770 - val_loss: 2.4149\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2735 - val_loss: 2.4130\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2693 - val_loss: 2.4119\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2665 - val_loss: 2.4188\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2633 - val_loss: 2.4120\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2625 - val_loss: 2.4101\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2570 - val_loss: 2.4109\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2544 - val_loss: 2.4089\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2507 - val_loss: 2.4065\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2447 - val_loss: 2.4034\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2454 - val_loss: 2.4032\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2414 - val_loss: 2.3962\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2385 - val_loss: 2.4076\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2391 - val_loss: 2.3948\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2347 - val_loss: 2.3987\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2326 - val_loss: 2.3986\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2280 - val_loss: 2.3981\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2294 - val_loss: 2.3966\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2242 - val_loss: 2.3954\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2232 - val_loss: 2.3943\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2194 - val_loss: 2.3935\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2168 - val_loss: 2.3924\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2126 - val_loss: 2.3949\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2155 - val_loss: 2.3916\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2087 - val_loss: 2.3985\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2080 - val_loss: 2.3953\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2040 - val_loss: 2.4008\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2075 - val_loss: 2.3999\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2035 - val_loss: 2.4173\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2044 - val_loss: 2.3919\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1963 - val_loss: 2.3983\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2020 - val_loss: 2.3885\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1973 - val_loss: 2.3900\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1940 - val_loss: 2.3883\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1914 - val_loss: 2.3899\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1939 - val_loss: 2.3923\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1892 - val_loss: 2.3953\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1863 - val_loss: 2.4012\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1880 - val_loss: 2.3987\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1839 - val_loss: 2.3943\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1820 - val_loss: 2.3867\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1833 - val_loss: 2.3867\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1784 - val_loss: 2.3919\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1782 - val_loss: 2.3925\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1734 - val_loss: 2.3939\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1792 - val_loss: 2.3904\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1735 - val_loss: 2.3872\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1720 - val_loss: 2.3835\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1699 - val_loss: 2.3845\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1701 - val_loss: 2.3846\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1667 - val_loss: 2.3870\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1666 - val_loss: 2.3825\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1658 - val_loss: 2.3895\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1630 - val_loss: 2.3888\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1614 - val_loss: 2.3895\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1544 - val_loss: 2.3901\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.3855\n",
      "[CV] END learning_rate=0.0013598826922812779, n_hidden=1, n_neurons=61; total time=  10.3s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 23.3930 - val_loss: 9.4800\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 7.0353 - val_loss: 4.3425\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.7687 - val_loss: 3.7156\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.0142 - val_loss: 3.4245\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.5942 - val_loss: 3.2417\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3291 - val_loss: 3.1021\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1528 - val_loss: 3.0047\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0158 - val_loss: 2.9233\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9136 - val_loss: 2.8578\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8229 - val_loss: 2.8002\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7571 - val_loss: 2.7501\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7024 - val_loss: 2.7102\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6587 - val_loss: 2.6725\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6189 - val_loss: 2.6544\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5836 - val_loss: 2.6238\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5556 - val_loss: 2.6155\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5308 - val_loss: 2.5894\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5145 - val_loss: 2.5719\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4934 - val_loss: 2.5661\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4760 - val_loss: 2.5522\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4616 - val_loss: 2.5412\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4487 - val_loss: 2.5310\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4337 - val_loss: 2.5351\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4236 - val_loss: 2.5177\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4130 - val_loss: 2.5209\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4065 - val_loss: 2.5129\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3956 - val_loss: 2.5043\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3899 - val_loss: 2.5031\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3804 - val_loss: 2.4931\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3757 - val_loss: 2.4894\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3641 - val_loss: 2.4966\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3624 - val_loss: 2.4856\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3545 - val_loss: 2.4848\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3483 - val_loss: 2.4826\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3481 - val_loss: 2.4822\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3357 - val_loss: 2.4697\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3363 - val_loss: 2.4745\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3300 - val_loss: 2.4723\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3282 - val_loss: 2.4712\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3226 - val_loss: 2.4684\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3185 - val_loss: 2.4669\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3151 - val_loss: 2.4694\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3075 - val_loss: 2.4612\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3053 - val_loss: 2.4666\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3082 - val_loss: 2.4555\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2972 - val_loss: 2.4543\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2935 - val_loss: 2.4612\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2934 - val_loss: 2.4581\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2881 - val_loss: 2.4611\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2858 - val_loss: 2.4555\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2837 - val_loss: 2.4541\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2822 - val_loss: 2.4599\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2786 - val_loss: 2.4532\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2729 - val_loss: 2.4568\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2709 - val_loss: 2.4702\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2659 - val_loss: 2.4556\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2654 - val_loss: 2.4514\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2601 - val_loss: 2.4394\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2598 - val_loss: 2.4418\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2587 - val_loss: 2.4407\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2549 - val_loss: 2.4480\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2501 - val_loss: 2.4455\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2507 - val_loss: 2.4365\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2477 - val_loss: 2.4323\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2436 - val_loss: 2.4319\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2440 - val_loss: 2.4328\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2423 - val_loss: 2.4382\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2395 - val_loss: 2.4281\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2361 - val_loss: 2.4305\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2333 - val_loss: 2.4422\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2315 - val_loss: 2.4309\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2295 - val_loss: 2.4340\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2278 - val_loss: 2.4282\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2254 - val_loss: 2.4210\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2267 - val_loss: 2.4221\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2212 - val_loss: 2.4198\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2209 - val_loss: 2.4182\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2193 - val_loss: 2.4226\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2166 - val_loss: 2.4218\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2105 - val_loss: 2.4191\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2143 - val_loss: 2.4193\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2117 - val_loss: 2.4233\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2081 - val_loss: 2.4199\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2076 - val_loss: 2.4253\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2045 - val_loss: 2.4174\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2044 - val_loss: 2.4174\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2031 - val_loss: 2.4157\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1979 - val_loss: 2.4142\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1988 - val_loss: 2.4117\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1958 - val_loss: 2.4188\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1958 - val_loss: 2.4241\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1938 - val_loss: 2.4196\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1929 - val_loss: 2.4215\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1899 - val_loss: 2.4116\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1889 - val_loss: 2.4170\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1870 - val_loss: 2.4150\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1862 - val_loss: 2.4131\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1876 - val_loss: 2.4143\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1838 - val_loss: 2.4124\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1811 - val_loss: 2.4107\n",
      "26/26 [==============================] - 0s 999us/step - loss: 2.3309\n",
      "[CV] END learning_rate=0.0013598826922812779, n_hidden=1, n_neurons=61; total time=  10.3s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 18.2127 - val_loss: 7.5943\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.0899 - val_loss: 4.6960\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.6812 - val_loss: 4.0756\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.0290 - val_loss: 3.6999\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.6059 - val_loss: 3.4132\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3046 - val_loss: 3.2164\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0883 - val_loss: 3.0741\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9332 - val_loss: 2.9693\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8215 - val_loss: 2.8966\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7383 - val_loss: 2.8351\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6731 - val_loss: 2.7784\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6214 - val_loss: 2.7526\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5812 - val_loss: 2.7133\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5454 - val_loss: 2.6847\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5182 - val_loss: 2.6758\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4953 - val_loss: 2.6572\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4761 - val_loss: 2.6394\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4534 - val_loss: 2.6290\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4410 - val_loss: 2.6110\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4243 - val_loss: 2.6065\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4139 - val_loss: 2.5986\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4004 - val_loss: 2.5948\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3914 - val_loss: 2.5754\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3782 - val_loss: 2.5573\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3689 - val_loss: 2.5638\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3636 - val_loss: 2.5532\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3531 - val_loss: 2.5371\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3467 - val_loss: 2.5376\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3392 - val_loss: 2.5286\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3332 - val_loss: 2.5325\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3273 - val_loss: 2.5229\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3210 - val_loss: 2.5246\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3170 - val_loss: 2.5231\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3113 - val_loss: 2.5133\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3024 - val_loss: 2.5071\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3073 - val_loss: 2.5030\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2908 - val_loss: 2.5222\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2925 - val_loss: 2.5074\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2850 - val_loss: 2.4935\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2853 - val_loss: 2.4876\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2804 - val_loss: 2.4888\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2746 - val_loss: 2.4979\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2698 - val_loss: 2.4932\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2681 - val_loss: 2.4871\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2652 - val_loss: 2.4930\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2617 - val_loss: 2.4964\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2570 - val_loss: 2.4813\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2520 - val_loss: 2.4823\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2512 - val_loss: 2.4718\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2490 - val_loss: 2.4732\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2445 - val_loss: 2.4720\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2410 - val_loss: 2.4740\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2401 - val_loss: 2.4801\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2369 - val_loss: 2.4649\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2366 - val_loss: 2.4660\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2342 - val_loss: 2.4686\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2290 - val_loss: 2.4668\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2272 - val_loss: 2.4715\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2223 - val_loss: 2.4563\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2225 - val_loss: 2.4689\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2186 - val_loss: 2.4592\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2175 - val_loss: 2.4589\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.2163 - val_loss: 2.4570\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2164 - val_loss: 2.4583\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2102 - val_loss: 2.4483\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2103 - val_loss: 2.4487\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2086 - val_loss: 2.4573\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2058 - val_loss: 2.4541\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2036 - val_loss: 2.4601\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2013 - val_loss: 2.4473\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1993 - val_loss: 2.4457\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1956 - val_loss: 2.4668\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1961 - val_loss: 2.4598\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1938 - val_loss: 2.4539\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1909 - val_loss: 2.4370\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1898 - val_loss: 2.4399\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1882 - val_loss: 2.4461\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1871 - val_loss: 2.4451\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1812 - val_loss: 2.4487\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1843 - val_loss: 2.4431\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1824 - val_loss: 2.4577\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1806 - val_loss: 2.4562\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1813 - val_loss: 2.4425\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1694 - val_loss: 2.4782\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1793 - val_loss: 2.4371\n",
      "26/26 [==============================] - 0s 920us/step - loss: 2.4452\n",
      "[CV] END learning_rate=0.0013598826922812779, n_hidden=1, n_neurons=61; total time=   8.7s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 32.4093 - val_loss: 29.5238\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 26.0916 - val_loss: 24.2268\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 21.6609 - val_loss: 20.4020\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 18.3755 - val_loss: 17.5024\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 15.8298 - val_loss: 15.2342\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 13.7955 - val_loss: 13.3667\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 12.1086 - val_loss: 11.8307\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 10.7085 - val_loss: 10.5283\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 9.5193 - val_loss: 9.4294\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 8.5183 - val_loss: 8.4988\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 7.6663 - val_loss: 7.7060\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.9434 - val_loss: 7.0297\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.3245 - val_loss: 6.4493\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.7955 - val_loss: 5.9478\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.3403 - val_loss: 5.5199\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.9522 - val_loss: 5.1525\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.6192 - val_loss: 4.8358\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.3335 - val_loss: 4.5654\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.0890 - val_loss: 4.3336\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.8819 - val_loss: 4.1328\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.7029 - val_loss: 3.9598\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.5489 - val_loss: 3.8102\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4166 - val_loss: 3.6792\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3015 - val_loss: 3.5659\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2016 - val_loss: 3.4675\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1158 - val_loss: 3.3816\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0412 - val_loss: 3.3080\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9776 - val_loss: 3.2433\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9215 - val_loss: 3.1866\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8731 - val_loss: 3.1377\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8310 - val_loss: 3.0955\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7951 - val_loss: 3.0565\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7624 - val_loss: 3.0231\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7346 - val_loss: 2.9930\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7098 - val_loss: 2.9669\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6884 - val_loss: 2.9434\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6697 - val_loss: 2.9216\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6525 - val_loss: 2.9033\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6378 - val_loss: 2.8873\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6247 - val_loss: 2.8728\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6128 - val_loss: 2.8597\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6022 - val_loss: 2.8475\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5932 - val_loss: 2.8374\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5845 - val_loss: 2.8272\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5766 - val_loss: 2.8179\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5696 - val_loss: 2.8093\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5633 - val_loss: 2.8006\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5574 - val_loss: 2.7943\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5519 - val_loss: 2.7874\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5474 - val_loss: 2.7815\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5429 - val_loss: 2.7754\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5389 - val_loss: 2.7713\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5352 - val_loss: 2.7663\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5316 - val_loss: 2.7611\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5284 - val_loss: 2.7574\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5252 - val_loss: 2.7534\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5225 - val_loss: 2.7496\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5198 - val_loss: 2.7458\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5172 - val_loss: 2.7425\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5149 - val_loss: 2.7389\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5129 - val_loss: 2.7353\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5105 - val_loss: 2.7329\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5088 - val_loss: 2.7296\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5069 - val_loss: 2.7267\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5048 - val_loss: 2.7246\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5030 - val_loss: 2.7222\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5009 - val_loss: 2.7197\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4996 - val_loss: 2.7175\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4981 - val_loss: 2.7156\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4967 - val_loss: 2.7135\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4952 - val_loss: 2.7115\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4941 - val_loss: 2.7104\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4929 - val_loss: 2.7089\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4917 - val_loss: 2.7078\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4901 - val_loss: 2.7061\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4891 - val_loss: 2.7046\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4881 - val_loss: 2.7033\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4868 - val_loss: 2.7019\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4861 - val_loss: 2.7010\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4850 - val_loss: 2.6994\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4843 - val_loss: 2.6979\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4833 - val_loss: 2.6972\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4822 - val_loss: 2.6963\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4813 - val_loss: 2.6949\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4807 - val_loss: 2.6934\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4801 - val_loss: 2.6927\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4792 - val_loss: 2.6927\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4783 - val_loss: 2.6925\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4779 - val_loss: 2.6910\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4772 - val_loss: 2.6892\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4765 - val_loss: 2.6882\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4759 - val_loss: 2.6876\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4752 - val_loss: 2.6860\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4745 - val_loss: 2.6851\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4736 - val_loss: 2.6842\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4731 - val_loss: 2.6834\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4730 - val_loss: 2.6829\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4718 - val_loss: 2.6834\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4719 - val_loss: 2.6825\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4712 - val_loss: 2.6818\n",
      "26/26 [==============================] - 0s 981us/step - loss: 2.5047\n",
      "[CV] END learning_rate=0.0007742325871412366, n_hidden=0, n_neurons=67; total time=   9.6s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 35.3207 - val_loss: 30.5848\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 27.8283 - val_loss: 24.6099\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 22.7690 - val_loss: 20.4302\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 19.1099 - val_loss: 17.3877\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 16.3684 - val_loss: 15.0069\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 14.1732 - val_loss: 13.0859\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 12.3804 - val_loss: 11.5122\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 10.8979 - val_loss: 10.2019\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 9.6596 - val_loss: 9.0956\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 8.6097 - val_loss: 8.1623\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 7.7206 - val_loss: 7.3662\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.9651 - val_loss: 6.6923\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.3223 - val_loss: 6.1233\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.7795 - val_loss: 5.6358\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.3144 - val_loss: 5.2181\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.9162 - val_loss: 4.8647\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.5764 - val_loss: 4.5563\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.2841 - val_loss: 4.2963\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 4.0348 - val_loss: 4.0753\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.8240 - val_loss: 3.8867\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.6438 - val_loss: 3.7245\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4895 - val_loss: 3.5871\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3583 - val_loss: 3.4681\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2447 - val_loss: 3.3664\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1480 - val_loss: 3.2789\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0637 - val_loss: 3.2021\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9916 - val_loss: 3.1374\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9297 - val_loss: 3.0812\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8757 - val_loss: 3.0336\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8296 - val_loss: 2.9913\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.7896 - val_loss: 2.9552\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7559 - val_loss: 2.9233\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7252 - val_loss: 2.8968\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7002 - val_loss: 2.8720\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6771 - val_loss: 2.8521\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6578 - val_loss: 2.8345\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6413 - val_loss: 2.8192\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6265 - val_loss: 2.8059\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6127 - val_loss: 2.7944\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6020 - val_loss: 2.7833\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5915 - val_loss: 2.7738\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5830 - val_loss: 2.7660\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5753 - val_loss: 2.7585\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5683 - val_loss: 2.7518\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5620 - val_loss: 2.7459\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5567 - val_loss: 2.7401\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5514 - val_loss: 2.7355\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5469 - val_loss: 2.7307\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5424 - val_loss: 2.7266\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5388 - val_loss: 2.7226\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5353 - val_loss: 2.7196\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5323 - val_loss: 2.7156\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5296 - val_loss: 2.7122\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5267 - val_loss: 2.7099\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5243 - val_loss: 2.7079\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5218 - val_loss: 2.7051\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5194 - val_loss: 2.7024\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5176 - val_loss: 2.7008\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5159 - val_loss: 2.6995\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5140 - val_loss: 2.6977\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5122 - val_loss: 2.6951\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5105 - val_loss: 2.6932\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5093 - val_loss: 2.6914\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5078 - val_loss: 2.6888\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5067 - val_loss: 2.6880\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5053 - val_loss: 2.6865\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5042 - val_loss: 2.6851\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5029 - val_loss: 2.6832\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5022 - val_loss: 2.6831\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5006 - val_loss: 2.6829\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4999 - val_loss: 2.6823\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4990 - val_loss: 2.6803\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4976 - val_loss: 2.6790\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4968 - val_loss: 2.6786\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4957 - val_loss: 2.6779\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4945 - val_loss: 2.6768\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4937 - val_loss: 2.6763\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4935 - val_loss: 2.6742\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4929 - val_loss: 2.6736\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4919 - val_loss: 2.6724\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4911 - val_loss: 2.6715\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4903 - val_loss: 2.6703\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4895 - val_loss: 2.6701\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4889 - val_loss: 2.6691\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4883 - val_loss: 2.6683\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4878 - val_loss: 2.6681\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4868 - val_loss: 2.6671\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4866 - val_loss: 2.6670\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4857 - val_loss: 2.6664\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4854 - val_loss: 2.6660\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4850 - val_loss: 2.6657\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4845 - val_loss: 2.6666\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4836 - val_loss: 2.6662\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4835 - val_loss: 2.6646\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4830 - val_loss: 2.6660\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4828 - val_loss: 2.6648\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4822 - val_loss: 2.6650\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4816 - val_loss: 2.6635\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4811 - val_loss: 2.6627\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4809 - val_loss: 2.6613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 879us/step - loss: 2.4556\n",
      "[CV] END learning_rate=0.0007742325871412366, n_hidden=0, n_neurons=67; total time=   9.5s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 29.0184 - val_loss: 25.9256\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 24.3627 - val_loss: 22.0390\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 20.7889 - val_loss: 18.9728\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 17.9270 - val_loss: 16.5114\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 15.6049 - val_loss: 14.4736\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 13.6708 - val_loss: 12.7674\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 12.0465 - val_loss: 11.3215\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 10.6674 - val_loss: 10.1037\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 9.5102 - val_loss: 9.0656\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 8.5219 - val_loss: 8.1737\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 7.6759 - val_loss: 7.4097\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 6.9489 - val_loss: 6.7633\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.3348 - val_loss: 6.2065\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.8082 - val_loss: 5.7333\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.3590 - val_loss: 5.3304\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.9765 - val_loss: 4.9819\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.6475 - val_loss: 4.6847\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.3658 - val_loss: 4.4296\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.1239 - val_loss: 4.2099\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.9154 - val_loss: 4.0208\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.7354 - val_loss: 3.8584\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.5820 - val_loss: 3.7181\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4504 - val_loss: 3.5983\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3370 - val_loss: 3.4931\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2363 - val_loss: 3.4011\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1490 - val_loss: 3.3224\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0744 - val_loss: 3.2541\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0094 - val_loss: 3.1950\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9539 - val_loss: 3.1431\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9045 - val_loss: 3.0974\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8602 - val_loss: 3.0572\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8215 - val_loss: 3.0226\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7875 - val_loss: 2.9921\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7583 - val_loss: 2.9651\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7311 - val_loss: 2.9415\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7084 - val_loss: 2.9198\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6877 - val_loss: 2.9010\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6691 - val_loss: 2.8839\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6527 - val_loss: 2.8691\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6375 - val_loss: 2.8553\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6238 - val_loss: 2.8418\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6110 - val_loss: 2.8303\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5993 - val_loss: 2.8201\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5897 - val_loss: 2.8106\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5800 - val_loss: 2.8015\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5710 - val_loss: 2.7923\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5630 - val_loss: 2.7844\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5552 - val_loss: 2.7771\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5484 - val_loss: 2.7712\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5419 - val_loss: 2.7651\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5358 - val_loss: 2.7585\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5302 - val_loss: 2.7533\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5249 - val_loss: 2.7489\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5201 - val_loss: 2.7448\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5154 - val_loss: 2.7409\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5112 - val_loss: 2.7368\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5071 - val_loss: 2.7335\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5032 - val_loss: 2.7294\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4996 - val_loss: 2.7257\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4961 - val_loss: 2.7221\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4929 - val_loss: 2.7186\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4895 - val_loss: 2.7153\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4869 - val_loss: 2.7124\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4840 - val_loss: 2.7099\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4813 - val_loss: 2.7070\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4790 - val_loss: 2.7045\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4760 - val_loss: 2.7016\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4738 - val_loss: 2.6997\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4717 - val_loss: 2.6970\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4692 - val_loss: 2.6948\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4673 - val_loss: 2.6935\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4654 - val_loss: 2.6904\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4631 - val_loss: 2.6889\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4615 - val_loss: 2.6864\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4597 - val_loss: 2.6849\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4583 - val_loss: 2.6838\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4567 - val_loss: 2.6826\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4551 - val_loss: 2.6806\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4542 - val_loss: 2.6787\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4528 - val_loss: 2.6783\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4507 - val_loss: 2.6766\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4498 - val_loss: 2.6747\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4483 - val_loss: 2.6743\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4472 - val_loss: 2.6737\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4458 - val_loss: 2.6727\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4448 - val_loss: 2.6720\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4439 - val_loss: 2.6714\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4426 - val_loss: 2.6701\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4416 - val_loss: 2.6688\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4404 - val_loss: 2.6678\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4398 - val_loss: 2.6661\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4388 - val_loss: 2.6645\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4378 - val_loss: 2.6630\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4369 - val_loss: 2.6633\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4362 - val_loss: 2.6625\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4356 - val_loss: 2.6617\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4350 - val_loss: 2.6609\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4340 - val_loss: 2.6589\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4335 - val_loss: 2.6592\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4325 - val_loss: 2.6582\n",
      "26/26 [==============================] - 0s 999us/step - loss: 2.5345\n",
      "[CV] END learning_rate=0.0007742325871412366, n_hidden=0, n_neurons=67; total time=   9.6s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 23.9838 - val_loss: 15.1910\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 11.1780 - val_loss: 8.3243\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.4349 - val_loss: 5.3479\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.3463 - val_loss: 4.0316\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4192 - val_loss: 3.4240\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9900 - val_loss: 3.1213\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7796 - val_loss: 2.9724\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6771 - val_loss: 2.8953\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6249 - val_loss: 2.8461\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5918 - val_loss: 2.8141\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5705 - val_loss: 2.7889\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5545 - val_loss: 2.7760\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5447 - val_loss: 2.7632\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5370 - val_loss: 2.7494\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5290 - val_loss: 2.7417\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5249 - val_loss: 2.7365\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5213 - val_loss: 2.7277\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5171 - val_loss: 2.7216\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5132 - val_loss: 2.7194\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5100 - val_loss: 2.7141\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5075 - val_loss: 2.7115\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5064 - val_loss: 2.7099\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5028 - val_loss: 2.7099\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5002 - val_loss: 2.6978\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5000 - val_loss: 2.7013\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4976 - val_loss: 2.6972\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4969 - val_loss: 2.6956\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4944 - val_loss: 2.7049\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4922 - val_loss: 2.6955\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4920 - val_loss: 2.6881\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4907 - val_loss: 2.6893\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4881 - val_loss: 2.6841\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4887 - val_loss: 2.6811\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4861 - val_loss: 2.6808\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4851 - val_loss: 2.6780\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4841 - val_loss: 2.6776\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4822 - val_loss: 2.6794\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4816 - val_loss: 2.6814\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4797 - val_loss: 2.6783\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4800 - val_loss: 2.6852\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4787 - val_loss: 2.6717\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4781 - val_loss: 2.6730\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4765 - val_loss: 2.6733\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4747 - val_loss: 2.6727\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4749 - val_loss: 2.6688\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4727 - val_loss: 2.6639\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4747 - val_loss: 2.6613\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4703 - val_loss: 2.6653\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4699 - val_loss: 2.6650\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4701 - val_loss: 2.6587\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4688 - val_loss: 2.6593\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4664 - val_loss: 2.6602\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4662 - val_loss: 2.6563\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4634 - val_loss: 2.6589\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4649 - val_loss: 2.6547\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4628 - val_loss: 2.6522\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4622 - val_loss: 2.6506\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4605 - val_loss: 2.6508\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4584 - val_loss: 2.6533\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4574 - val_loss: 2.6441\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4572 - val_loss: 2.6473\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4580 - val_loss: 2.6495\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4552 - val_loss: 2.6461\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4552 - val_loss: 2.6475\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4563 - val_loss: 2.6430\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4525 - val_loss: 2.6380\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4523 - val_loss: 2.6398\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4528 - val_loss: 2.6354\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4514 - val_loss: 2.6379\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4507 - val_loss: 2.6344\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4502 - val_loss: 2.6360\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4478 - val_loss: 2.6321\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4486 - val_loss: 2.6312\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4472 - val_loss: 2.6315\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4429 - val_loss: 2.6313\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4454 - val_loss: 2.6272\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4441 - val_loss: 2.6256\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4440 - val_loss: 2.6283\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4441 - val_loss: 2.6271\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4413 - val_loss: 2.6263\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4418 - val_loss: 2.6222\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4402 - val_loss: 2.6271\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4391 - val_loss: 2.6197\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4357 - val_loss: 2.6170\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4376 - val_loss: 2.6177\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4349 - val_loss: 2.6145\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4355 - val_loss: 2.6164\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4371 - val_loss: 2.6149\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4350 - val_loss: 2.6158\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4331 - val_loss: 2.6093\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4331 - val_loss: 2.6066\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4317 - val_loss: 2.6109\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4320 - val_loss: 2.6146\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4301 - val_loss: 2.6109\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4322 - val_loss: 2.6084\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4292 - val_loss: 2.6047\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.4304 - val_loss: 2.5999\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4281 - val_loss: 2.5995\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4281 - val_loss: 2.6053\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4271 - val_loss: 2.6079\n",
      "26/26 [==============================] - 0s 960us/step - loss: 2.4573\n",
      "[CV] END learning_rate=0.0039951434737393755, n_hidden=0, n_neurons=90; total time=   9.7s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 24.5813 - val_loss: 14.8097\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 11.3161 - val_loss: 8.1954\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.5784 - val_loss: 5.3331\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.4817 - val_loss: 4.0284\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.5287 - val_loss: 3.4219\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0795 - val_loss: 3.1239\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8535 - val_loss: 2.9597\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7303 - val_loss: 2.8684\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6586 - val_loss: 2.8154\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6119 - val_loss: 2.7811\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5780 - val_loss: 2.7502\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5554 - val_loss: 2.7260\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5366 - val_loss: 2.7083\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5239 - val_loss: 2.6924\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5094 - val_loss: 2.6823\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5007 - val_loss: 2.6709\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4932 - val_loss: 2.6668\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4880 - val_loss: 2.6569\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4802 - val_loss: 2.6527\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4759 - val_loss: 2.6536\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4735 - val_loss: 2.6373\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4716 - val_loss: 2.6323\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4707 - val_loss: 2.6379\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4669 - val_loss: 2.6381\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4647 - val_loss: 2.6289\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4637 - val_loss: 2.6264\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4615 - val_loss: 2.6297\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4594 - val_loss: 2.6353\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4584 - val_loss: 2.6214\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4592 - val_loss: 2.6190\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4582 - val_loss: 2.6121\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4580 - val_loss: 2.6171\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4575 - val_loss: 2.6180\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4526 - val_loss: 2.6139\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4553 - val_loss: 2.6149\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4548 - val_loss: 2.6160\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4509 - val_loss: 2.6176\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4533 - val_loss: 2.6098\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4502 - val_loss: 2.6129\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4499 - val_loss: 2.6156\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4482 - val_loss: 2.6303\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4483 - val_loss: 2.6073\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4500 - val_loss: 2.6036\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4479 - val_loss: 2.5995\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4455 - val_loss: 2.6047\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4467 - val_loss: 2.6005\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4450 - val_loss: 2.6016\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4430 - val_loss: 2.5975\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4429 - val_loss: 2.6061\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4433 - val_loss: 2.5990\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4416 - val_loss: 2.5985\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4438 - val_loss: 2.5958\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4408 - val_loss: 2.5981\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4413 - val_loss: 2.5973\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4410 - val_loss: 2.5996\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4397 - val_loss: 2.5922\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4392 - val_loss: 2.5881\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4375 - val_loss: 2.5948\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4395 - val_loss: 2.5944\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4362 - val_loss: 2.5896\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4357 - val_loss: 2.5950\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4362 - val_loss: 2.5971\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4358 - val_loss: 2.5895\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4358 - val_loss: 2.5883\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4320 - val_loss: 2.5903\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4348 - val_loss: 2.5875\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4324 - val_loss: 2.5987\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4346 - val_loss: 2.5876\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4320 - val_loss: 2.5841\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4319 - val_loss: 2.5843\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4312 - val_loss: 2.5800\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4310 - val_loss: 2.5960\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4308 - val_loss: 2.5775\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4304 - val_loss: 2.5791\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4277 - val_loss: 2.5801\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4298 - val_loss: 2.5772\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4277 - val_loss: 2.5687\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4282 - val_loss: 2.5743\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4263 - val_loss: 2.5731\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4285 - val_loss: 2.5756\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4257 - val_loss: 2.5811\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4262 - val_loss: 2.5849\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4257 - val_loss: 2.5721\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4258 - val_loss: 2.5710\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4243 - val_loss: 2.5844\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4237 - val_loss: 2.5777\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4220 - val_loss: 2.5749\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.3845\n",
      "[CV] END learning_rate=0.0039951434737393755, n_hidden=0, n_neurons=90; total time=   8.3s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 23.7554 - val_loss: 14.9851\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 11.2141 - val_loss: 8.1401\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 6.3829 - val_loss: 5.2058\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.2907 - val_loss: 3.9178\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3666 - val_loss: 3.3329\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9474 - val_loss: 3.0486\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7408 - val_loss: 2.9114\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6380 - val_loss: 2.8414\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5824 - val_loss: 2.7981\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5461 - val_loss: 2.7701\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5225 - val_loss: 2.7509\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5065 - val_loss: 2.7362\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4926 - val_loss: 2.7211\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4855 - val_loss: 2.7092\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4754 - val_loss: 2.6990\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4706 - val_loss: 2.7009\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4623 - val_loss: 2.6879\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4586 - val_loss: 2.6831\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4520 - val_loss: 2.6776\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4511 - val_loss: 2.6717\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4469 - val_loss: 2.6690\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4441 - val_loss: 2.6700\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4410 - val_loss: 2.6724\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4370 - val_loss: 2.6592\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4372 - val_loss: 2.6594\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4350 - val_loss: 2.6572\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4337 - val_loss: 2.6594\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4335 - val_loss: 2.6691\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4313 - val_loss: 2.6539\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4280 - val_loss: 2.6498\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4273 - val_loss: 2.6497\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4247 - val_loss: 2.6563\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4256 - val_loss: 2.6505\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4240 - val_loss: 2.6472\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4218 - val_loss: 2.6415\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4217 - val_loss: 2.6414\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4198 - val_loss: 2.6399\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4193 - val_loss: 2.6351\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4178 - val_loss: 2.6328\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4171 - val_loss: 2.6318\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4147 - val_loss: 2.6371\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4155 - val_loss: 2.6340\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4145 - val_loss: 2.6282\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4128 - val_loss: 2.6268\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4132 - val_loss: 2.6273\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4110 - val_loss: 2.6306\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4108 - val_loss: 2.6245\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4094 - val_loss: 2.6302\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4099 - val_loss: 2.6263\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4075 - val_loss: 2.6234\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4076 - val_loss: 2.6279\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4067 - val_loss: 2.6109\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4044 - val_loss: 2.6162\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4063 - val_loss: 2.6210\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4045 - val_loss: 2.6119\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4030 - val_loss: 2.6132\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4029 - val_loss: 2.6079\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4006 - val_loss: 2.6139\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3997 - val_loss: 2.6086\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4018 - val_loss: 2.6061\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4001 - val_loss: 2.6050\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3991 - val_loss: 2.6061\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3985 - val_loss: 2.6082\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3989 - val_loss: 2.6032\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3973 - val_loss: 2.6068\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3967 - val_loss: 2.6032\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3959 - val_loss: 2.6010\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3958 - val_loss: 2.6087\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3933 - val_loss: 2.6022\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3939 - val_loss: 2.6092\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3928 - val_loss: 2.6062\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3922 - val_loss: 2.5971\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3913 - val_loss: 2.6017\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3914 - val_loss: 2.6072\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3906 - val_loss: 2.6017\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3902 - val_loss: 2.6009\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3898 - val_loss: 2.5986\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3862 - val_loss: 2.6087\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3883 - val_loss: 2.5944\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3875 - val_loss: 2.5973\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3867 - val_loss: 2.5931\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3868 - val_loss: 2.5981\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3857 - val_loss: 2.5891\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3829 - val_loss: 2.6044\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3865 - val_loss: 2.5934\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3839 - val_loss: 2.5917\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3817 - val_loss: 2.6009\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3834 - val_loss: 2.5907\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3816 - val_loss: 2.5841\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3826 - val_loss: 2.5825\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3820 - val_loss: 2.5861\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3809 - val_loss: 2.5817\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3806 - val_loss: 2.5810\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3807 - val_loss: 2.5787\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3797 - val_loss: 2.5806\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3789 - val_loss: 2.5848\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3775 - val_loss: 2.5980\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3784 - val_loss: 2.5863\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3787 - val_loss: 2.5835\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3760 - val_loss: 2.5822\n",
      "26/26 [==============================] - 0s 880us/step - loss: 2.4761\n",
      "[CV] END learning_rate=0.0039951434737393755, n_hidden=0, n_neurons=90; total time=   9.7s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 7.4922 - val_loss: 3.6525\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0598 - val_loss: 2.6723\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5921 - val_loss: 2.6437\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4995 - val_loss: 2.6446\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4825 - val_loss: 2.5682\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4269 - val_loss: 2.5636\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4356 - val_loss: 2.5733\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4295 - val_loss: 2.5567\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4148 - val_loss: 2.6671\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3845 - val_loss: 2.5270\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3919 - val_loss: 2.5837\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4039 - val_loss: 2.5366\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3732 - val_loss: 2.5904\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3559 - val_loss: 2.5041\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3669 - val_loss: 2.4699\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3605 - val_loss: 2.4719\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3717 - val_loss: 2.5135\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3429 - val_loss: 2.5384\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3188 - val_loss: 2.5675\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3601 - val_loss: 2.4725\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3652 - val_loss: 2.5110\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3454 - val_loss: 2.5418\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3814 - val_loss: 2.4384\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3156 - val_loss: 2.6039\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3316 - val_loss: 2.4636\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3299 - val_loss: 2.4360\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3214 - val_loss: 2.4801\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3205 - val_loss: 2.5351\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3254 - val_loss: 2.5923\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3367 - val_loss: 2.4456\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3367 - val_loss: 2.5062\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3377 - val_loss: 2.5344\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.3292 - val_loss: 2.4430\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3392 - val_loss: 2.5773\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3257 - val_loss: 3.7729\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3283 - val_loss: 2.4971\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.4273\n",
      "[CV] END learning_rate=0.012710197087588831, n_hidden=1, n_neurons=4; total time=   3.9s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 11.7249 - val_loss: 5.7707\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.8458 - val_loss: 3.7066\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2378 - val_loss: 2.9704\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8986 - val_loss: 2.8769\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6828 - val_loss: 2.6812\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5831 - val_loss: 2.7829\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5406 - val_loss: 2.6250\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4964 - val_loss: 2.6184\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4576 - val_loss: 2.6512\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4510 - val_loss: 2.6075\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4292 - val_loss: 2.5921\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4175 - val_loss: 2.5953\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4066 - val_loss: 2.6882\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4226 - val_loss: 2.5479\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4108 - val_loss: 2.5355\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3935 - val_loss: 2.7584\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4086 - val_loss: 2.5110\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3928 - val_loss: 2.4931\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3923 - val_loss: 2.5869\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3931 - val_loss: 2.5011\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3616 - val_loss: 2.5720\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3555 - val_loss: 2.6206\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3565 - val_loss: 2.4527\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3553 - val_loss: 2.4835\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3590 - val_loss: 2.4351\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3333 - val_loss: 2.4637\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3535 - val_loss: 2.5984\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3364 - val_loss: 2.6474\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3330 - val_loss: 2.4541\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3515 - val_loss: 2.4859\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3432 - val_loss: 2.4675\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3351 - val_loss: 2.4194\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3172 - val_loss: 2.4058\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3262 - val_loss: 2.5813\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3185 - val_loss: 2.6633\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3615 - val_loss: 2.4618\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3130 - val_loss: 2.4478\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3192 - val_loss: 2.4484\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3228 - val_loss: 2.4579\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3260 - val_loss: 2.5049\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3379 - val_loss: 2.5810\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3340 - val_loss: 2.4064\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2713 - val_loss: 2.5726\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.4963\n",
      "[CV] END learning_rate=0.012710197087588831, n_hidden=1, n_neurons=4; total time=   4.5s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 7.6671 - val_loss: 3.6946\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9041 - val_loss: 2.8034\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5798 - val_loss: 2.8420\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4989 - val_loss: 2.8078\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4239 - val_loss: 2.5609\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4287 - val_loss: 2.7245\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4052 - val_loss: 2.5952\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4139 - val_loss: 2.7962\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4029 - val_loss: 2.6127\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3646 - val_loss: 2.5627\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3502 - val_loss: 2.5720\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3576 - val_loss: 2.5584\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3508 - val_loss: 2.7739\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3680 - val_loss: 2.5543\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3131 - val_loss: 2.5569\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3317 - val_loss: 2.4892\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3232 - val_loss: 2.4867\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3079 - val_loss: 2.4827\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3192 - val_loss: 2.9572\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3288 - val_loss: 2.4769\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3212 - val_loss: 2.5045\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3098 - val_loss: 2.4955\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3231 - val_loss: 2.7851\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3326 - val_loss: 2.4444\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3086 - val_loss: 2.4765\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2947 - val_loss: 2.6540\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2947 - val_loss: 2.5239\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3132 - val_loss: 2.5412\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3206 - val_loss: 2.5053\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3024 - val_loss: 2.4850\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2825 - val_loss: 2.4429\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2869 - val_loss: 2.5323\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3060 - val_loss: 2.4472\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2990 - val_loss: 2.5873\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3107 - val_loss: 2.5102\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2851 - val_loss: 2.5530\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2845 - val_loss: 2.4651\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2891 - val_loss: 2.4641\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2925 - val_loss: 2.5147\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3025 - val_loss: 2.6994\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2775 - val_loss: 2.4621\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.4012\n",
      "[CV] END learning_rate=0.012710197087588831, n_hidden=1, n_neurons=4; total time=   4.4s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 25.7610 - val_loss: 14.4454\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 10.0165 - val_loss: 5.8005\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.8055 - val_loss: 4.4326\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.8700 - val_loss: 4.0633\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.3084 - val_loss: 3.8281\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.9280 - val_loss: 3.6361\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.6502 - val_loss: 3.4834\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4389 - val_loss: 3.3501\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2700 - val_loss: 3.2414\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1357 - val_loss: 3.1493\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0303 - val_loss: 3.0771\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9427 - val_loss: 3.0071\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8645 - val_loss: 2.9615\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8089 - val_loss: 2.9034\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7556 - val_loss: 2.8572\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7108 - val_loss: 2.8212\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6724 - val_loss: 2.7797\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6411 - val_loss: 2.7465\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6114 - val_loss: 2.7168\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5812 - val_loss: 2.6929\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5555 - val_loss: 2.6719\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5341 - val_loss: 2.6569\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5173 - val_loss: 2.6327\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4979 - val_loss: 2.6238\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4822 - val_loss: 2.6092\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4657 - val_loss: 2.5977\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4523 - val_loss: 2.5771\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4394 - val_loss: 2.5648\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4279 - val_loss: 2.5532\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4139 - val_loss: 2.5526\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4042 - val_loss: 2.5455\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3929 - val_loss: 2.5333\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3831 - val_loss: 2.5232\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.3734 - val_loss: 2.5178\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3663 - val_loss: 2.5110\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3551 - val_loss: 2.5125\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3477 - val_loss: 2.5017\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3375 - val_loss: 2.5057\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3357 - val_loss: 2.4917\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.3270 - val_loss: 2.4824\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.3197 - val_loss: 2.4754\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.3123 - val_loss: 2.4762\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.3078 - val_loss: 2.4711\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3044 - val_loss: 2.4662\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2964 - val_loss: 2.4580\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2920 - val_loss: 2.4540\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2868 - val_loss: 2.4570\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2818 - val_loss: 2.4544\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2785 - val_loss: 2.4528\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2714 - val_loss: 2.4547\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2705 - val_loss: 2.4439\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2661 - val_loss: 2.4418\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2620 - val_loss: 2.4381\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2584 - val_loss: 2.4363\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2541 - val_loss: 2.4349\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2447 - val_loss: 2.4296\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2400 - val_loss: 2.4383\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2427 - val_loss: 2.4318\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2389 - val_loss: 2.4241\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2337 - val_loss: 2.4270\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2324 - val_loss: 2.4298\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2276 - val_loss: 2.4169\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2228 - val_loss: 2.4226\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2202 - val_loss: 2.4208\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2183 - val_loss: 2.4149\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2144 - val_loss: 2.4242\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2140 - val_loss: 2.4131\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2103 - val_loss: 2.4132\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2045 - val_loss: 2.4116\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2060 - val_loss: 2.4145\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2019 - val_loss: 2.4160\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2009 - val_loss: 2.4076\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.1969 - val_loss: 2.4064\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1938 - val_loss: 2.4126\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1922 - val_loss: 2.4120\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1907 - val_loss: 2.4090\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1856 - val_loss: 2.4272\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1840 - val_loss: 2.4132\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1792 - val_loss: 2.4065\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1768 - val_loss: 2.4119\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.1780 - val_loss: 2.4054\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.1731 - val_loss: 2.4152\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1712 - val_loss: 2.4220\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1739 - val_loss: 2.4007\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1658 - val_loss: 2.4194\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1675 - val_loss: 2.3995\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1651 - val_loss: 2.4066\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1572 - val_loss: 2.3998\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1616 - val_loss: 2.4008\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1540 - val_loss: 2.3997\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1574 - val_loss: 2.4013\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1532 - val_loss: 2.3998\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1501 - val_loss: 2.4162\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1515 - val_loss: 2.3938\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1472 - val_loss: 2.3996\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1456 - val_loss: 2.3962\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1428 - val_loss: 2.3935\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1405 - val_loss: 2.3941\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1393 - val_loss: 2.3915\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1368 - val_loss: 2.3922\n",
      "26/26 [==============================] - 0s 879us/step - loss: 2.3745\n",
      "[CV] END learning_rate=0.0006253699615508369, n_hidden=2, n_neurons=82; total time=  11.3s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 24.2117 - val_loss: 12.2482\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 8.8581 - val_loss: 5.0906\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.5222 - val_loss: 4.2625\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.7465 - val_loss: 3.9371\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.2615 - val_loss: 3.6885\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.9027 - val_loss: 3.4831\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.6357 - val_loss: 3.3166\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4273 - val_loss: 3.1715\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2646 - val_loss: 3.0634\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1325 - val_loss: 2.9767\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0253 - val_loss: 2.9044\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9399 - val_loss: 2.8343\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8734 - val_loss: 2.7893\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8136 - val_loss: 2.7484\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7593 - val_loss: 2.7157\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7163 - val_loss: 2.6731\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6767 - val_loss: 2.6482\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6431 - val_loss: 2.6237\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6134 - val_loss: 2.6094\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5852 - val_loss: 2.5910\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5610 - val_loss: 2.5845\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5410 - val_loss: 2.5633\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5210 - val_loss: 2.5485\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5024 - val_loss: 2.5341\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4865 - val_loss: 2.5224\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4690 - val_loss: 2.5492\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4606 - val_loss: 2.5113\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4437 - val_loss: 2.5011\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4318 - val_loss: 2.4993\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4192 - val_loss: 2.4932\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4072 - val_loss: 2.4846\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3977 - val_loss: 2.4813\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3839 - val_loss: 2.4711\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3802 - val_loss: 2.4717\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3703 - val_loss: 2.4670\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3622 - val_loss: 2.4653\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3541 - val_loss: 2.4663\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3445 - val_loss: 2.4690\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3377 - val_loss: 2.4625\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.3318 - val_loss: 2.4571\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.3237 - val_loss: 2.4582\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.3134 - val_loss: 2.4459\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3090 - val_loss: 2.4681\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3058 - val_loss: 2.4539\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2978 - val_loss: 2.4488\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2913 - val_loss: 2.4413\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2863 - val_loss: 2.4385\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2787 - val_loss: 2.4414\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2730 - val_loss: 2.4545\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2689 - val_loss: 2.4307\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2671 - val_loss: 2.4357\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2593 - val_loss: 2.4294\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2554 - val_loss: 2.4251\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2508 - val_loss: 2.4299\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2451 - val_loss: 2.4269\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2400 - val_loss: 2.4182\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2410 - val_loss: 2.4176\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2336 - val_loss: 2.4182\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2292 - val_loss: 2.4172\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2266 - val_loss: 2.4162\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2206 - val_loss: 2.4218\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2157 - val_loss: 2.4174\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2142 - val_loss: 2.4213\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2088 - val_loss: 2.4254\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2086 - val_loss: 2.4136\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2026 - val_loss: 2.4116\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1987 - val_loss: 2.4137\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1981 - val_loss: 2.4089\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1936 - val_loss: 2.4097\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1936 - val_loss: 2.4098\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1869 - val_loss: 2.4212\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1846 - val_loss: 2.4173\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1802 - val_loss: 2.4057\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1790 - val_loss: 2.4075\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1797 - val_loss: 2.4081\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1763 - val_loss: 2.4049\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1720 - val_loss: 2.4170\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1663 - val_loss: 2.4001\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1669 - val_loss: 2.4037\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1628 - val_loss: 2.4005\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1614 - val_loss: 2.3961\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1605 - val_loss: 2.4010\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1559 - val_loss: 2.4009\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1540 - val_loss: 2.4019\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1512 - val_loss: 2.4027\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1483 - val_loss: 2.4019\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1457 - val_loss: 2.4037\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1419 - val_loss: 2.3974\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1420 - val_loss: 2.4084\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1382 - val_loss: 2.4145\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1372 - val_loss: 2.3959\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1257 - val_loss: 2.4122\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1342 - val_loss: 2.4025\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1304 - val_loss: 2.4050\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1288 - val_loss: 2.4204\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1269 - val_loss: 2.4293\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1274 - val_loss: 2.4096\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1229 - val_loss: 2.4079\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1200 - val_loss: 2.4015\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1180 - val_loss: 2.4094\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.3178\n",
      "[CV] END learning_rate=0.0006253699615508369, n_hidden=2, n_neurons=82; total time=  27.3s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 4ms/step - loss: 26.0000 - val_loss: 15.0964\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 9.1727 - val_loss: 5.3739\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 5.0741 - val_loss: 4.4800\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.5029 - val_loss: 4.1431\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.1490 - val_loss: 3.8983\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.8718 - val_loss: 3.7157\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.6583 - val_loss: 3.5547\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4852 - val_loss: 3.4326\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3437 - val_loss: 3.3245\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2225 - val_loss: 3.2396\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1235 - val_loss: 3.1565\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0329 - val_loss: 3.0952\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9592 - val_loss: 3.0457\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8931 - val_loss: 2.9823\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8311 - val_loss: 2.9151\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7783 - val_loss: 2.8794\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7312 - val_loss: 2.8621\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6928 - val_loss: 2.8122\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6534 - val_loss: 2.7815\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6205 - val_loss: 2.7581\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5859 - val_loss: 2.7548\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5601 - val_loss: 2.7046\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5342 - val_loss: 2.6912\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5138 - val_loss: 2.6778\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4951 - val_loss: 2.6529\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4749 - val_loss: 2.6331\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4567 - val_loss: 2.6363\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4414 - val_loss: 2.6122\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4259 - val_loss: 2.6019\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4132 - val_loss: 2.6075\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4008 - val_loss: 2.5772\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3911 - val_loss: 2.5715\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3796 - val_loss: 2.5851\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3665 - val_loss: 2.5609\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3579 - val_loss: 2.5512\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3486 - val_loss: 2.5489\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3381 - val_loss: 2.5634\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3336 - val_loss: 2.5411\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3215 - val_loss: 2.5223\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3181 - val_loss: 2.5221\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3072 - val_loss: 2.5116\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3051 - val_loss: 2.5136\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2944 - val_loss: 2.5219\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2917 - val_loss: 2.5089\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2847 - val_loss: 2.5056\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2817 - val_loss: 2.5147\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2751 - val_loss: 2.5009\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2684 - val_loss: 2.4934\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2638 - val_loss: 2.4929\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2618 - val_loss: 2.4765\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2552 - val_loss: 2.4730\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2502 - val_loss: 2.4834\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2411 - val_loss: 2.4923\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2399 - val_loss: 2.4918\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2380 - val_loss: 2.4640\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2346 - val_loss: 2.4668\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2294 - val_loss: 2.4788\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2298 - val_loss: 2.4663\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2222 - val_loss: 2.4592\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2236 - val_loss: 2.4645\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2179 - val_loss: 2.4657\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2141 - val_loss: 2.4674\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2126 - val_loss: 2.4622\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2076 - val_loss: 2.4568\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2054 - val_loss: 2.4493\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1998 - val_loss: 2.4643\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1998 - val_loss: 2.4434\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1976 - val_loss: 2.4528\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1944 - val_loss: 2.4448\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1916 - val_loss: 2.4491\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1892 - val_loss: 2.4518\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1869 - val_loss: 2.4387\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1845 - val_loss: 2.4454\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1808 - val_loss: 2.4532\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1818 - val_loss: 2.4320\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1746 - val_loss: 2.4432\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1727 - val_loss: 2.4343\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1722 - val_loss: 2.4332\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1676 - val_loss: 2.4300\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1679 - val_loss: 2.4322\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1653 - val_loss: 2.4444\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1632 - val_loss: 2.4207\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1649 - val_loss: 2.4242\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1569 - val_loss: 2.4553\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1600 - val_loss: 2.4261\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1558 - val_loss: 2.4644\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1550 - val_loss: 2.4364\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1496 - val_loss: 2.4543\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1528 - val_loss: 2.4505\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1472 - val_loss: 2.4203\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1469 - val_loss: 2.4289\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1466 - val_loss: 2.4224\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1438 - val_loss: 2.4248\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1426 - val_loss: 2.4229\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1402 - val_loss: 2.4248\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1359 - val_loss: 2.4450\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1395 - val_loss: 2.4247\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1317 - val_loss: 2.4321\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1322 - val_loss: 2.4351\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1323 - val_loss: 2.4190\n",
      "26/26 [==============================] - 0s 999us/step - loss: 2.4451\n",
      "[CV] END learning_rate=0.0006253699615508369, n_hidden=2, n_neurons=82; total time=  10.7s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 5.7271 - val_loss: 5.5312\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2670 - val_loss: 3.5302\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6058 - val_loss: 2.7021\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7568 - val_loss: 3.8457\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4591 - val_loss: 2.5939\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3314 - val_loss: 2.9580\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4104 - val_loss: 3.0420\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2282 - val_loss: 3.0974\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1803 - val_loss: 2.9776\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6027 - val_loss: 2.8454\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2080 - val_loss: 2.8596\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1667 - val_loss: 2.7538\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1063 - val_loss: 3.6713\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2557 - val_loss: 4.0963\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1985 - val_loss: 2.5318\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0749 - val_loss: 2.6715\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1536 - val_loss: 2.6380\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0418 - val_loss: 2.8631\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0332 - val_loss: 3.0289\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1065 - val_loss: 2.5518\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9958 - val_loss: 2.6107\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9551 - val_loss: 2.8982\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0604 - val_loss: 3.5173\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0147 - val_loss: 2.5921\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0359 - val_loss: 2.5363\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.4949\n",
      "[CV] END learning_rate=0.02111716044526189, n_hidden=2, n_neurons=91; total time=   3.1s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 6.6390 - val_loss: 3.6650\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.5403 - val_loss: 4.5672\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0675 - val_loss: 4.3872\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8819 - val_loss: 5.1946\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5135 - val_loss: 2.4275\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3552 - val_loss: 2.7858\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4784 - val_loss: 2.4477\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4080 - val_loss: 2.4951\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3591 - val_loss: 2.4007\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2416 - val_loss: 3.0097\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2489 - val_loss: 2.4513\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6049 - val_loss: 3.9346\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2992 - val_loss: 2.6270\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1909 - val_loss: 2.9817\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1672 - val_loss: 2.5357\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1375 - val_loss: 2.5579\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0903 - val_loss: 2.3377\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0464 - val_loss: 2.4770\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0379 - val_loss: 3.2591\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0674 - val_loss: 2.9755\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2425 - val_loss: 2.6092\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0282 - val_loss: 2.5709\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9867 - val_loss: 2.5524\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1287 - val_loss: 2.7083\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0000 - val_loss: 2.5071\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 1.9175 - val_loss: 3.8323\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9108 - val_loss: 2.6199\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.4633\n",
      "[CV] END learning_rate=0.02111716044526189, n_hidden=2, n_neurons=91; total time=   3.3s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 4.3820 - val_loss: 2.9893\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9918 - val_loss: 3.0818\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7588 - val_loss: 4.9103\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7628 - val_loss: 2.8139\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4920 - val_loss: 6.4734\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8741 - val_loss: 4.9616\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5389 - val_loss: 3.1097\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3122 - val_loss: 2.6197\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4812 - val_loss: 2.4773\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4363 - val_loss: 4.8136\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3733 - val_loss: 2.5694\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2840 - val_loss: 6.4709\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2404 - val_loss: 3.4952\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3742 - val_loss: 2.4540\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2079 - val_loss: 2.4562\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1779 - val_loss: 2.8510\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1280 - val_loss: 2.6849\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1066 - val_loss: 2.8627\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1115 - val_loss: 2.8801\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1062 - val_loss: 2.5495\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0816 - val_loss: 6.4001\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1811 - val_loss: 2.5501\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0328 - val_loss: 6.6080\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1773 - val_loss: 2.7688\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.7368\n",
      "[CV] END learning_rate=0.02111716044526189, n_hidden=2, n_neurons=91; total time=   2.9s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 4ms/step - loss: 7.4453 - val_loss: 4.0858\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.1039 - val_loss: 3.0396\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5832 - val_loss: 3.5132\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4637 - val_loss: 2.4887\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3196 - val_loss: 4.0653\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3016 - val_loss: 3.0916\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2716 - val_loss: 2.5544\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2700 - val_loss: 2.5104\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2531 - val_loss: 3.8726\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2736 - val_loss: 2.3960\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1689 - val_loss: 5.7279\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1741 - val_loss: 2.6379\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1346 - val_loss: 2.5617\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1765 - val_loss: 2.5623\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1095 - val_loss: 2.5327\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0711 - val_loss: 2.7722\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0731 - val_loss: 2.9381\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0889 - val_loss: 2.4345\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0223 - val_loss: 2.8054\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0423 - val_loss: 2.4317\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.4974\n",
      "[CV] END learning_rate=0.006383466440191768, n_hidden=3, n_neurons=96; total time=   2.7s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 4ms/step - loss: 7.9796 - val_loss: 3.3763\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9550 - val_loss: 2.7258\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5347 - val_loss: 3.1728\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4085 - val_loss: 2.5412\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3387 - val_loss: 2.4918\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2963 - val_loss: 2.6731\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3198 - val_loss: 2.3700\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2421 - val_loss: 2.4270\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2471 - val_loss: 3.1475\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2203 - val_loss: 2.5498\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1707 - val_loss: 2.3698\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1204 - val_loss: 2.5543\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0888 - val_loss: 2.4303\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2284 - val_loss: 2.4059\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0746 - val_loss: 2.3505\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1081 - val_loss: 2.8576\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1015 - val_loss: 2.5171\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0441 - val_loss: 2.6014\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0308 - val_loss: 3.0886\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0274 - val_loss: 2.5460\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0174 - val_loss: 2.4438\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9993 - val_loss: 2.5137\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0233 - val_loss: 2.3985\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9503 - val_loss: 2.4826\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9690 - val_loss: 2.4772\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.4406\n",
      "[CV] END learning_rate=0.006383466440191768, n_hidden=3, n_neurons=96; total time=   3.2s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 4ms/step - loss: 6.8195 - val_loss: 2.9975\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8279 - val_loss: 2.7232\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4901 - val_loss: 2.9245\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.4132 - val_loss: 2.7458\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3881 - val_loss: 2.4389\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3423 - val_loss: 2.4890\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.2804 - val_loss: 2.5006\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.2847 - val_loss: 2.5426\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.2721 - val_loss: 2.6151\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.1864 - val_loss: 2.5052\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.1764 - val_loss: 2.4267\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1767 - val_loss: 2.5169\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1414 - val_loss: 2.4828\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1002 - val_loss: 2.7296\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0839 - val_loss: 2.4856\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1074 - val_loss: 2.4481\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0725 - val_loss: 2.4402\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1366 - val_loss: 2.4684\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0574 - val_loss: 2.6170\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0516 - val_loss: 2.3997\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0020 - val_loss: 2.4933\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9934 - val_loss: 2.4333\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9821 - val_loss: 2.4721\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0196 - val_loss: 3.2435\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9892 - val_loss: 2.7464\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9501 - val_loss: 2.4760\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9230 - val_loss: 2.5139\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9222 - val_loss: 2.4619\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9054 - val_loss: 2.4642\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 1.9169 - val_loss: 2.4998\n",
      "26/26 [==============================] - 0s 999us/step - loss: 2.4997\n",
      "[CV] END learning_rate=0.006383466440191768, n_hidden=3, n_neurons=96; total time=   4.0s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 13.4922 - val_loss: 4.2150\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.0320 - val_loss: 3.4527\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.3558 - val_loss: 3.1335\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0413 - val_loss: 2.9171\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8340 - val_loss: 2.7813\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7250 - val_loss: 2.7167\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6327 - val_loss: 2.6415\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5783 - val_loss: 2.6130\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5288 - val_loss: 2.5903\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4941 - val_loss: 2.5709\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4611 - val_loss: 2.5394\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4396 - val_loss: 2.5325\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4146 - val_loss: 2.5183\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3945 - val_loss: 2.5370\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3826 - val_loss: 2.4833\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3674 - val_loss: 2.4714\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3497 - val_loss: 2.4657\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3368 - val_loss: 2.4560\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3210 - val_loss: 2.4466\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3139 - val_loss: 2.4430\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3028 - val_loss: 2.4631\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2915 - val_loss: 2.4581\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2866 - val_loss: 2.4419\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2782 - val_loss: 2.4309\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2693 - val_loss: 2.4236\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2607 - val_loss: 2.4222\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2482 - val_loss: 2.4503\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2288 - val_loss: 2.4285\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2408 - val_loss: 2.4289\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2313 - val_loss: 2.4175\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2232 - val_loss: 2.4166\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2172 - val_loss: 2.4117\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2158 - val_loss: 2.4116\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2074 - val_loss: 2.4372\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2048 - val_loss: 2.4238\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1989 - val_loss: 2.4162\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1897 - val_loss: 2.4087\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1868 - val_loss: 2.4027\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1769 - val_loss: 2.4015\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1830 - val_loss: 2.3945\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1763 - val_loss: 2.3984\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1719 - val_loss: 2.3942\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1660 - val_loss: 2.3977\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1654 - val_loss: 2.4056\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1568 - val_loss: 2.4001\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1524 - val_loss: 2.4006\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1492 - val_loss: 2.3932\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.1445 - val_loss: 2.3991\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1431 - val_loss: 2.4015\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1384 - val_loss: 2.3982\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1331 - val_loss: 2.3945\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1304 - val_loss: 2.3873\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1216 - val_loss: 2.4043\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1296 - val_loss: 2.3877\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1230 - val_loss: 2.3915\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1209 - val_loss: 2.3953\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1170 - val_loss: 2.3867\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1144 - val_loss: 2.3981\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1114 - val_loss: 2.3927\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1073 - val_loss: 2.3851\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1048 - val_loss: 2.3833\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0992 - val_loss: 2.3921\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0971 - val_loss: 2.3944\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0954 - val_loss: 2.3749\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0904 - val_loss: 2.3877\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0976 - val_loss: 2.3819\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0883 - val_loss: 2.3872\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0864 - val_loss: 2.3830\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0838 - val_loss: 2.3857\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0777 - val_loss: 2.3824\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0759 - val_loss: 2.3902\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0787 - val_loss: 2.3806\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0718 - val_loss: 2.3842\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.0730 - val_loss: 2.3814\n",
      "26/26 [==============================] - 0s 960us/step - loss: 2.3654\n",
      "[CV] END learning_rate=0.0024104283615771307, n_hidden=1, n_neurons=91; total time=   7.7s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 14.9338 - val_loss: 4.5182\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.7770 - val_loss: 3.6222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.6279 - val_loss: 3.1920\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.2171 - val_loss: 2.9963\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.9624 - val_loss: 2.8553\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7990 - val_loss: 2.7415\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6858 - val_loss: 2.6855\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6134 - val_loss: 2.6504\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5575 - val_loss: 2.5937\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5121 - val_loss: 2.5744\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4799 - val_loss: 2.5424\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4444 - val_loss: 2.5313\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4257 - val_loss: 2.5144\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3993 - val_loss: 2.4987\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3838 - val_loss: 2.4734\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3699 - val_loss: 2.4656\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3513 - val_loss: 2.4857\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3443 - val_loss: 2.4855\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3266 - val_loss: 2.4843\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3245 - val_loss: 2.4806\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3138 - val_loss: 2.4567\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2974 - val_loss: 2.4332\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2968 - val_loss: 2.4568\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2883 - val_loss: 2.4622\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2833 - val_loss: 2.4465\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2714 - val_loss: 2.4411\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2672 - val_loss: 2.4361\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2576 - val_loss: 2.4383\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2541 - val_loss: 2.4734\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2470 - val_loss: 2.4095\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2371 - val_loss: 2.4312\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2375 - val_loss: 2.4336\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2254 - val_loss: 2.4055\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2260 - val_loss: 2.4182\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2211 - val_loss: 2.4155\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2158 - val_loss: 2.4486\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.2129 - val_loss: 2.4331\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.2113 - val_loss: 2.4282\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.2028 - val_loss: 2.4034\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 2.1988 - val_loss: 2.3971\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.1957 - val_loss: 2.4062\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1956 - val_loss: 2.3984\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1865 - val_loss: 2.3911\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1876 - val_loss: 2.3951\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1864 - val_loss: 2.4035\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1847 - val_loss: 2.3987\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1774 - val_loss: 2.3984\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1682 - val_loss: 2.3916\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1738 - val_loss: 2.3904\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1685 - val_loss: 2.4071\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1682 - val_loss: 2.3962\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1660 - val_loss: 2.4002\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1558 - val_loss: 2.4136\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1533 - val_loss: 2.4143\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1570 - val_loss: 2.3810\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1532 - val_loss: 2.3982\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1484 - val_loss: 2.4080\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1435 - val_loss: 2.4041\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1451 - val_loss: 2.4089\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1364 - val_loss: 2.3965\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1409 - val_loss: 2.4170\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1270 - val_loss: 2.4029\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1289 - val_loss: 2.4015\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1246 - val_loss: 2.3804\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1277 - val_loss: 2.4033\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1170 - val_loss: 2.4139\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1196 - val_loss: 2.3954\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1112 - val_loss: 2.4143\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1123 - val_loss: 2.3979\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1092 - val_loss: 2.3878\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1123 - val_loss: 2.3968\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1047 - val_loss: 2.4112\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1016 - val_loss: 2.4054\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1014 - val_loss: 2.4116\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.2933\n",
      "[CV] END learning_rate=0.0024104283615771307, n_hidden=1, n_neurons=91; total time=  10.6s\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 4ms/step - loss: 14.7060 - val_loss: 4.6800\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 4.2400 - val_loss: 3.7349\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.4773 - val_loss: 3.3447\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 3.0964 - val_loss: 3.1216\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.8688 - val_loss: 2.9660\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.7282 - val_loss: 2.8826\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.6319 - val_loss: 2.8076\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5585 - val_loss: 2.7291\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 2ms/step - loss: 2.5086 - val_loss: 2.6920\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4661 - val_loss: 2.6655\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4302 - val_loss: 2.6366\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.4028 - val_loss: 2.6338\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3800 - val_loss: 2.6136\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3660 - val_loss: 2.5912\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3496 - val_loss: 2.5860\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3390 - val_loss: 2.5534\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3193 - val_loss: 2.5830\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3137 - val_loss: 2.5539\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.3061 - val_loss: 2.5272\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2922 - val_loss: 2.5429\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2872 - val_loss: 2.5049\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2794 - val_loss: 2.5264\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2678 - val_loss: 2.5243\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2643 - val_loss: 2.5017\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2561 - val_loss: 2.4962\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2529 - val_loss: 2.5185\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2496 - val_loss: 2.5097\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2422 - val_loss: 2.5042\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2394 - val_loss: 2.5133\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2351 - val_loss: 2.5095\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2295 - val_loss: 2.4819\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2242 - val_loss: 2.4979\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2263 - val_loss: 2.4834\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2105 - val_loss: 2.4966\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2084 - val_loss: 2.5025\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.2070 - val_loss: 2.4579\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1983 - val_loss: 2.4841\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1990 - val_loss: 2.4798\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 2.2013 - val_loss: 2.4895\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.1908 - val_loss: 2.4984\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 2.1752 - val_loss: 2.4695\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1882 - val_loss: 2.4622\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1741 - val_loss: 2.4753\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1854 - val_loss: 2.4779\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1804 - val_loss: 2.4596\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 2ms/step - loss: 2.1733 - val_loss: 2.4723\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.5399\n",
      "[CV] END learning_rate=0.0024104283615771307, n_hidden=1, n_neurons=91; total time=   5.6s\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 1s 3ms/step - loss: 20.8415 - val_loss: 7.2075\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 5.9944 - val_loss: 4.2267\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 4.4134 - val_loss: 3.6797\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 3.8546 - val_loss: 3.4025\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 3.5124 - val_loss: 3.2110\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 3.2753 - val_loss: 3.0617\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 3.0907 - val_loss: 2.9531\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.9566 - val_loss: 2.8690\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.8588 - val_loss: 2.7884\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.7796 - val_loss: 2.7397\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.7100 - val_loss: 2.7060\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.6547 - val_loss: 2.6642\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.6099 - val_loss: 2.6297\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.5716 - val_loss: 2.6069\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.5407 - val_loss: 2.5963\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.5101 - val_loss: 2.5717\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.4841 - val_loss: 2.5558\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.4606 - val_loss: 2.5400\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.4406 - val_loss: 2.5253\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.4232 - val_loss: 2.5100\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.4082 - val_loss: 2.5044\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3905 - val_loss: 2.4996\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3800 - val_loss: 2.4924\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3672 - val_loss: 2.4830\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3550 - val_loss: 2.4782\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3452 - val_loss: 2.4707\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3368 - val_loss: 2.4647\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3280 - val_loss: 2.4597\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3204 - val_loss: 2.4532\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3091 - val_loss: 2.4455\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.3026 - val_loss: 2.4638\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2985 - val_loss: 2.4472\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2921 - val_loss: 2.4407\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2856 - val_loss: 2.4365\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.2783 - val_loss: 2.4294\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2764 - val_loss: 2.4252\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.2674 - val_loss: 2.4226\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2633 - val_loss: 2.4198\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2595 - val_loss: 2.4326\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2564 - val_loss: 2.4163\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2493 - val_loss: 2.4262\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2480 - val_loss: 2.4117\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2418 - val_loss: 2.4125\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 2.2381 - val_loss: 2.4181\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2358 - val_loss: 2.4188\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 2.2327 - val_loss: 2.4098\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2282 - val_loss: 2.4222\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.4122\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2213 - val_loss: 2.4048\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2173 - val_loss: 2.4125\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.2148 - val_loss: 2.4096\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2113 - val_loss: 2.4004\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2096 - val_loss: 2.3974\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2074 - val_loss: 2.4048\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.2032 - val_loss: 2.4072\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1967 - val_loss: 2.3972\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1928 - val_loss: 2.4124\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1978 - val_loss: 2.3963\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.1947 - val_loss: 2.3965\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.1897 - val_loss: 2.3935\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1861 - val_loss: 2.3951\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1830 - val_loss: 2.4079\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1842 - val_loss: 2.3973\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1800 - val_loss: 2.4010\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1786 - val_loss: 2.3896\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1783 - val_loss: 2.3935\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1738 - val_loss: 2.3863\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1757 - val_loss: 2.3921\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1719 - val_loss: 2.3910\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1705 - val_loss: 2.3972\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1698 - val_loss: 2.3891\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1639 - val_loss: 2.3902\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 2.1625 - val_loss: 2.3916\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 2.1613 - val_loss: 2.3909\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1598 - val_loss: 2.3917\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1580 - val_loss: 2.3963\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.1556 - val_loss: 2.3890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000002233C516A30>,\n",
       "                   param_distributions={'learning_rate': array([0.01236022, 0.00196222, 0.00494489, 0.00453661, 0.00119409,\n",
       "       0.00743723, 0.00194198, 0.00430075, 0.00142693, 0.02886968,\n",
       "       0.00387698, 0.00127125, 0.00039058, 0.00799372, 0.00098373,\n",
       "       0.01051593, 0.0007416 , 0.0237713 , 0.001...\n",
       "       0.00043384, 0.02907572, 0.01200955, 0.00298007, 0.02456792]),\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 1061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(n_hidden=4, n_neurons=400, learning_rate=1e-3, input_shape=[13]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(x_train, y_train, epochs=100,\n",
    "                  validation_data=(x_val, y_val),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "6ea95a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neurons': 82, 'n_hidden': 2, 'learning_rate': 0.0006253699615508369}\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_279 (Dense)           (None, 82)                1148      \n",
      "                                                                 \n",
      " dense_280 (Dense)           (None, 82)                6806      \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 1)                 83        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,037\n",
      "Trainable params: 8,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c898b44",
   "metadata": {},
   "source": [
    "## 모델 만들기\n",
    "- 모델(점수예측)은 회귀모델이기 때문에 출력층에 활성화함수를 지정하지 않았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "id": "61060c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 만들기\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(13,)))\n",
    "model.add(Dense(400, activation = 'relu'))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e196c6",
   "metadata": {},
   "source": [
    "## 모델컴파일\n",
    "- 회귀문제 : MSE(loss) , MAE(eval)\n",
    "- 이진분류문제 : binary cross entropy(loss) , accuracy(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "id": "328fc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모멘텀(Momentum)은 관성이라는 물리학의 법칙을 응용한 방법입니다. 모멘텀 경사 하강법에 관성을 더 해줍니다. 모멘텀은 경사 하강법에서 계산된 접선의 기울기에 한 시점 전의 접선의 기울기값을 일정한 비율만큼 반영합니다. 이렇게 하면 마치 언덕에서 공이 내려올 때, 중간에 작은 웅덩이에 빠지더라도 관성의 힘으로 넘어서는 효과를 줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "id": "81504861",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "model.compile(loss='mse',\n",
    "              optimizer=sgd,metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21469388",
   "metadata": {},
   "source": [
    "# 텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "1ae1206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_dir ='.logs'\n",
    "\n",
    "tensor_board_cb = [TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4cd6ff",
   "metadata": {},
   "source": [
    "# 학습률 스케줄링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "id": "3970aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)\n",
    "\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f6c0c",
   "metadata": {},
   "source": [
    "## 모델학습 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "id": "c406fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "25/25 [==============================] - 1s 17ms/step - loss: 18.0102 - mae: 3.1621 - val_loss: 3.8318 - val_mae: 1.5663 - lr: 0.0100\n",
      "Epoch 2/500\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 3.8453 - mae: 1.5384 - val_loss: 4.0573 - val_mae: 1.6026 - lr: 0.0089\n",
      "Epoch 3/500\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 2.9946 - mae: 1.3359 - val_loss: 2.6294 - val_mae: 1.2583 - lr: 0.0079\n",
      "Epoch 4/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.6999 - mae: 1.2649 - val_loss: 2.4833 - val_mae: 1.2250 - lr: 0.0071\n",
      "Epoch 5/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.5305 - mae: 1.2290 - val_loss: 2.6396 - val_mae: 1.2594 - lr: 0.0063\n",
      "Epoch 6/500\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 2.3165 - mae: 1.1820 - val_loss: 2.4479 - val_mae: 1.2041 - lr: 0.0056\n",
      "Epoch 7/500\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 2.2475 - mae: 1.1687 - val_loss: 2.4281 - val_mae: 1.1987 - lr: 0.0050\n",
      "Epoch 8/500\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 2.1644 - mae: 1.1454 - val_loss: 2.5125 - val_mae: 1.2255 - lr: 0.0045\n",
      "Epoch 9/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.2403 - mae: 1.1698 - val_loss: 2.4052 - val_mae: 1.1912 - lr: 0.0040\n",
      "Epoch 10/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.1716 - mae: 1.1507 - val_loss: 2.4169 - val_mae: 1.2069 - lr: 0.0035\n",
      "Epoch 11/500\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 2.1299 - mae: 1.1377 - val_loss: 2.3888 - val_mae: 1.1954 - lr: 0.0032\n",
      "Epoch 12/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.1307 - mae: 1.1454 - val_loss: 2.4779 - val_mae: 1.2180 - lr: 0.0028\n",
      "Epoch 13/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.0939 - mae: 1.1345 - val_loss: 2.3916 - val_mae: 1.1942 - lr: 0.0025\n",
      "Epoch 14/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.0749 - mae: 1.1239 - val_loss: 2.3580 - val_mae: 1.1831 - lr: 0.0022\n",
      "Epoch 15/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.0598 - mae: 1.1199 - val_loss: 2.3891 - val_mae: 1.1933 - lr: 0.0020\n",
      "Epoch 16/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 2.0692 - mae: 1.1242 - val_loss: 2.4162 - val_mae: 1.2002 - lr: 0.0018\n",
      "Epoch 17/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.0477 - mae: 1.1165 - val_loss: 2.3723 - val_mae: 1.1887 - lr: 0.0016\n",
      "Epoch 18/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.0296 - mae: 1.1076 - val_loss: 2.4195 - val_mae: 1.2024 - lr: 0.0014\n",
      "Epoch 19/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.0400 - mae: 1.1126 - val_loss: 2.3572 - val_mae: 1.1859 - lr: 0.0013\n",
      "Epoch 20/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 2.0220 - mae: 1.1094 - val_loss: 2.3626 - val_mae: 1.1864 - lr: 0.0011\n",
      "Epoch 21/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 2.0159 - mae: 1.1058 - val_loss: 2.3634 - val_mae: 1.1869 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.0389 - mae: 1.1143 - val_loss: 2.3575 - val_mae: 1.1855 - lr: 8.9125e-04\n",
      "Epoch 23/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.9981 - mae: 1.1008 - val_loss: 2.3754 - val_mae: 1.1895 - lr: 7.9433e-04\n",
      "Epoch 24/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.9863 - mae: 1.0988 - val_loss: 2.3773 - val_mae: 1.1894 - lr: 7.0795e-04\n",
      "Epoch 25/500\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 1.9900 - mae: 1.1003 - val_loss: 2.3747 - val_mae: 1.1893 - lr: 6.3096e-04\n",
      "Epoch 26/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 1.9835 - mae: 1.0991 - val_loss: 2.3709 - val_mae: 1.1871 - lr: 5.6234e-04\n",
      "Epoch 27/500\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 1.9723 - mae: 1.0961 - val_loss: 2.3842 - val_mae: 1.1903 - lr: 5.0119e-04\n",
      "Epoch 28/500\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.9774 - mae: 1.0976 - val_loss: 2.3634 - val_mae: 1.1862 - lr: 4.4668e-04\n",
      "Epoch 29/500\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 1.9709 - mae: 1.0944 - val_loss: 2.3822 - val_mae: 1.1909 - lr: 3.9811e-04\n"
     ]
    }
   ],
   "source": [
    "#최상의 모델을 저장 \n",
    "cp= ModelCheckpoint('score_predict_best_model.h5', save_best_only=True)\n",
    "early_Stopping_cb = EarlyStopping(patience=10, monitor='val_loss',restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=500, batch_size=100, validation_data=(x_val,y_val), callbacks=[cp,tensor_board_cb,early_Stopping_cb,lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "fcf04db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 30328), started 1:58:45 ago. (Use '!kill 30328' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-85e3492757fee0b7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-85e3492757fee0b7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e472c7",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "c2fb1ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step - loss: 2.3280 - mae: 1.1719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.327975034713745, 1.171921730041504]"
      ]
     },
     "execution_count": 1071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168bdf1",
   "metadata": {},
   "source": [
    "## 예측\n",
    "- 학습하지 않은 22년 10월 8일 3경기의 데이터를 예측하고자 한다.\n",
    "- 단 이때 22년 10월 8일의 경기가 진행되지 않음을 가정하고 예측을 진행한다. 스코어예측이나 점수예측은 주로 경기 전에 진행되는\n",
    "  특성을 따른 것.\n",
    "- 때문에 모델에 input으로 들어가는 데이터는 각 구단의 직전 3경기의 평균값을 입력하고 실제 22년 10월 8일의 데이터와 비교한다.\n",
    "- 선발투수는 경기전 확정된 선발투수의 데이터로 입력값을 넣는다(직전 3경기 평균값X 당일 데이터O)\n",
    "|22-10-8|A구단 점수|B구단 점수|\n",
    "|------|----------|----------|\n",
    "|SSG(A) : 삼성(B)|1|6|\n",
    "|키움 : 두산|5|1|\n",
    "|한화 : NC|5|6|\n",
    "|LG : 롯데|2|3|\n",
    "|KT : KIA|7|2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "29ac08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    tmp = scaler.transform([x])\n",
    "    score = model.predict([tmp])\n",
    "    score = round(float(score),2) \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "c2ddeeb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "SSG vs 삼성 - 1.73 : 5.89\n",
      "키움 vs 두산 - 6.17 : 3.6\n",
      "한화 vs NC - 4.05 : 4.37\n",
      "LG vs 롯데 - 6.66 : 1.94\n",
      "KT vs KIA - 3.52 : 4.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SSG = [36.3,33.6,6.6,1,2.3,0,9.6,10,7.6,0.196,18,2.49,1.16]\n",
    "samsung = [41.6,38.6,12.6,0.3,2.3,0,8,8.6,9.3,0.325,19,6.00,1.52]\n",
    "dusan = [34.6,32.6,9.3,1,1.3,0,6.3,8,9,0.282,11.6,3.60,1.33]\n",
    "kiwum =[50,44,12,1,5.3,0.6,8.6,11.6,11.6,0.268,21.6,2.11,0.95]\n",
    "hanwha = [42.6,34.6,9,0,5.6,1,6.3,10.6,9,0.258,24.6,4.75,1.42]\n",
    "NC = [34.3,30.6,6.6,0.3,3,2,8.6,9,7,0.216,11.6,10.64,1.91]\n",
    "LG = [42.3,38.3,12.6,1,2.3,0.6,8.6,10,7,0.329,16.3,2.31,1.22]\n",
    "lotte = [35.6,33,8,1,2.3,0,8.6,7,9.3,0.242,16.3,1.86,1.24]\n",
    "KT = [34.6,33.6,8.3,1.3,0.6,0,9.3,7.3,8.6,0.243,9,5.27,1.74]\n",
    "KIA = [37.3,34.3,11.3,1.6,2.3,0,4.6,8.3,10,0.328,16.3,2.95,1.22]\n",
    "score_SSG = predict(SSG)\n",
    "score_samsung = predict(samsung)\n",
    "score_dusan = predict(dusan)\n",
    "score_kiwum = predict(kiwum)\n",
    "score_hanwha = predict(hanwha)\n",
    "score_NC = predict(NC)\n",
    "score_LG = predict(LG)\n",
    "score_lotte = predict(lotte)\n",
    "score_KT = predict(KT)\n",
    "score_KIA = predict(KIA)\n",
    "\n",
    "print(f\"SSG vs 삼성 - {score_SSG} : {score_samsung}\")\n",
    "print(f\"키움 vs 두산 - {score_kiwum} : {score_dusan}\")\n",
    "print(f\"한화 vs NC - {score_hanwha} : {score_NC}\")\n",
    "print(f\"LG vs 롯데 - {score_LG} : {score_lotte}\")\n",
    "print(f\"KT vs KIA - {score_KT} : {score_KIA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "3a31b285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "SSG vs 삼성 - 0.69 : 6.53\n",
      "키움 vs 두산 - 6.4 : 1.43\n",
      "한화 vs NC - 5.46 : 6.01\n",
      "LG vs 롯데 - 1.85 : 4.08\n",
      "KT vs KIA - 5.04 : 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SSG = [30,30,3,1,0,0,6,8,13,0.1,5,2.49,1.16]\n",
    "samsung = [35,31,10,2,1,3,5,8,8,0.322,11,6.00,1.52]\n",
    "dusan = [30,30,5,1,0,0,9,8,8,0.166,6,3.60,1.33]\n",
    "kiwum =[39,32,10,1,3,1,2,5,15,0.312,12,2.11,0.95]\n",
    "hanwha = [52,44,9,1,7,1,11,9,15,0.204,22,4.75,1.42]\n",
    "NC = [48,45,12,1,3,0,11,11,11,0.266,17,10.64,1.91]\n",
    "LG = [39,35,9,0,4,0,8,10,8,0.257,26,2.31,1.22]\n",
    "lotte = [38,31,9,1,5,1,5,11,6,0.29,19,1.86,1.24]\n",
    "KT = [40,36,9,2,3,1,7,1,19,0.25,15,5.27,1.74]\n",
    "KIA = [39,34,8,0,4,1,10,7,9,0.235,22,2.95,1.22]\n",
    "score_SSG = predict(SSG)\n",
    "score_samsung = predict(samsung)\n",
    "score_dusan = predict(dusan)\n",
    "score_kiwum = predict(kiwum)\n",
    "score_hanwha = predict(hanwha)\n",
    "score_NC = predict(NC)\n",
    "score_LG = predict(LG)\n",
    "score_lotte = predict(lotte)\n",
    "score_KT = predict(KT)\n",
    "score_KIA = predict(KIA)\n",
    "\n",
    "print(f\"SSG vs 삼성 - {score_SSG} : {score_samsung}\")\n",
    "print(f\"키움 vs 두산 - {score_kiwum} : {score_dusan}\")\n",
    "print(f\"한화 vs NC - {score_hanwha} : {score_NC}\")\n",
    "print(f\"LG vs 롯데 - {score_LG} : {score_lotte}\")\n",
    "print(f\"KT vs KIA - {score_KT} : {score_KIA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f48f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
